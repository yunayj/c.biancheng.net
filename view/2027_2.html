<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ -->
<!-- 启用Chromium高速渲染模式 -->
<meta name="renderer" content="webkit" />
<meta name="force-rendering" content="webkit"/>
<!-- 禁止百度转码 -->
<meta name="applicable-device" content="pc,mobile" />
<meta name="MobileOptimized" content="width" />
<meta name="HandheldFriendly" content="true" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<!-- 禁止识别电话号码 -->
<meta name="format-detection" content="telephone=no" />

<link rel="shortcut icon" href="../favicon_3.ico" />
<link href="../templets/new/style/common_2.css" rel="stylesheet" />
<title>Python Scrapy中文教程，Scrapy框架快速入门！</title>
<meta name="description" content="谈起爬虫必然要提起 Scrapy 框架，因为它能够帮助提升爬虫的效率，从而更好地实现爬虫。 Scrapy 是一个为了抓取网页数据、提取结构性数据而编写的应用框架，该框架是封装的，包含" />
</head>
<body>
<div id="topbar" class="clearfix">
	<ul id="product-type" class="left">
		<li>
			<a href="../m_biancheng_default_2.html"><span class="iconfont iconfont-home"></span>首页</a>
		</li>
		<li class="active">
			<a href="../sitemap/sitemap_2.html" rel="nofollow"><span class="iconfont iconfont-book"></span>教程</a>
		</li>
		<li>
			<a href="http://vip.biancheng.net/p/vip/show.php" rel="nofollow" target="_blank"><span class="iconfont iconfont-vip"></span>VIP会员</a>
		</li>
		<li>
			<a href="../fudao_biancheng_default.html" rel="nofollow" target="_blank"><span class="iconfont iconfont-fudao"></span>辅导班</a>
		</li>
		<li>
			<a href="niz69i_5.html" target="_blank"><span class="iconfont iconfont-chip"></span>嵌入式学习路线</a>
		</li>
		<!-- <li>
			<a href="https://www.54benniao.com/c_course/?from=biancheng" target="_blank"><span class="iconfont iconfont-c-course"></span>C语言高级课程</a>
		</li>
		<li>
			<a href="https://www.54benniao.com/java_course/?from=biancheng" target="_blank"><span class="iconfont iconfont-java-course"></span>Java高级课程</a>
		</li>
		<li>
			<a href="http://vip.biancheng.net/p/q2a/show.php" rel="nofollow" target="_blank"><span class="iconfont iconfont-q2a"></span>一对一答疑</a>
		</li> -->
	</ul>
</div>
<div id="header" class="clearfix">
	<a id="logo" class="left" href="../m_biancheng_default_2.html">
		<img height="26" src="../templets/new/images/logo_2.png" alt="C语言中文网" />
	</a>
	<ul id="nav-main" class="hover-none left clearfix">
		<li class="wap-yes"><a href="../m_biancheng_default_2.html">首页</a></li>
		<li><a href="../c/c_4.html">C语言教程</a></li>
		<li><a href="../cplus/cplus_2.html">C++教程</a></li>
		<li><a href="../python/python_2.html">Python教程</a></li>
		<li><a href="../java/java_2.html">Java教程</a></li>
		<li><a href="../linux_tutorial/linux_tutorial_2.html">Linux入门</a></li>
		<li><a href="../sitemap/sitemap_2.html" title="网站地图">更多&gt;&gt;</a></li>
	</ul>
	<a href="http://vip.biancheng.net/?from=topbar" class="user-info iconfont iconfont-user hover-none" target="_blank" rel="nofollow" title="用户中心"></a>
</div>
<div id="main-no-course" class="clearfix">
	<div class="arc-info">
		<span class="position"><span class="iconfont iconfont-home2"></span> <a href="../m_biancheng_default_2.html">首页</a> &gt; 编程笔记</span>
	</div>
	<div id="ggxc-position-bottom" class="ggxc-box"></div>
	<h1>Python Scrapy中文教程，Scrapy框架快速入门！</h1>
	<div id="ggxc-arctop-pc-1" class="ggxc-box"></div>
	<div id="arc-body">谈起爬虫必然要提起 Scrapy 框架，因为它能够帮助提升爬虫的效率，从而更好地实现爬虫。<br />
<br />
Scrapy 是一个为了抓取网页数据、提取结构性数据而编写的应用框架，该框架是封装的，包含 request （异步调度和处理）、下载器（多线程的 Downloader）、解析器（selector）和 twisted（异步处理）等。对于网站的内容爬取，其速度非常快捷。<br />
<br />
也许读者会感到迷惑，有这么好的爬虫框架，为什么前面的章节还要学习使用 requests 库请求网页数据。其实，requests 是一个功能十分强大的库，它能够满足大部分网页数据获取的需求。其工作原理是向服务器发送数据请求，至于数据的下载和解析，都需要自己处理，因而灵活性高；而由于 Scrapy 框架的封装，使得其灵活性降低。<br />
<br />
至于使用哪种爬虫方式，完全取决于个人的实际需求。在没有明确需求之前，笔者依然推荐初学者先选择 requests 库请求网页数据，而在业务实战中产生实际需求时，再考虑 Scrapy 框架。<br />
<h2>
	Scrapy 安装</h2>
直接使用 pip 安装 Scrapy 会产生一些错误的安装提示信息，导致 Scrapy 无法正常安装。当然，既然有问题出现，必然对应着许多的解决办法。在 <a href="http://www.lfd.uci.edu/～gohlke/pythonlibs" target="_blank">http://www.lfd.uci.edu/～gohlke/pythonlibs</a> 网站中，拥有很多适用于 Windows 的、已经编译好的 <a href='../python/python_2.html' target='_blank'>Python</a> 第三方库，读者只需根据错误的安装提示信息找到相应的包，进行安装即可，此处不对这种方法进行详细讲解。本小节主要介绍如何在 PyCharm 中安装 Scrapy。<br />
<br />
第一步，选择 Anaconda 3 作为编译环境。在 PyCharm 中单击左上角 File 选项，单击&ldquo;Settings&rdquo;按钮，弹出如图 1 所示界面，然后展开 Project Interpreter 的下拉菜单，选择 Anaconda 3 的下拉菜单：
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q04923126_2.gif" /><br />
	图 1</div>
<p class="info-box">
	这里需要提前安装 Anaconda，安装之后才能添加 Anaconda 编译环境。</p>
第二步，安装 Scrapy。单击图 1 界面右上角绿色加号按钮，弹出如图 2 所示的界面。输入并搜索&ldquo;scrapy&rdquo;，然后单击&ldquo;Install Package&rdquo;按钮。等待，直至出现&ldquo;Pakage&lsquo;scrapy&rsquo; installed successfully&rdquo;：
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q05134B1_2.jpg" /><br />
	图 2</div>
<h2>
	案例：用 Scrapy 抓取股票行情</h2>
本案例将使用 Scrapy 框架，抓取某证券网站A股行情。爬取过程分为以下五步：
<ul>
	<li>
		第一步，创建Scrapy爬虫项目；</li>
	<li>
		第二步，定义一个item容器；</li>
	<li>
		第三步，定义settings文件进行基本爬虫设置；</li>
	<li>
		第四步，编写爬虫逻辑；</li>
	<li>
		第五步，代码调试。</li>
</ul>
<h4>
	创建Scrapy爬虫项目</h4>
调出 CMD，输入如下代码并按【Enter】键，创建 Scrapy 爬虫项目：<br />
<p class="info-box">
	scrapy startproject stockstar</p>
其中 scrapy startproject 是固定命令，stockstar 是笔者设置的工程名字。<br />
<br />
运行上述代码的目的是创建相应的项目文件，如下所示：
<ul>
	<li>
		放置 spider 代码的目录文件 spiders（用于编写爬虫）。</li>
	<li>
		项目中的 item 文件 items.py（用于保存所抓取的数据的容器，其存储方式类似于 Python 的字典）。</li>
	<li>
		项目的中间件</li>
	<li>
		middlewares.py（提供一种简便的机制，通过允许插入自定义代码来拓展 Scrapy 的功能）。</li>
	<li>
		项目的 pipelines 文件 pipelines.py（核心处理器）。</li>
	<li>
		项目的设置文件 settings.py。</li>
	<li>
		项目的配置文件 scrapy.cfg。</li>
</ul>
<br />
项目结构如图 3 所示：
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q0525B15_2.gif" /><br />
	图 3 项目结构</div>
<br />
创建 scrapy 项目以后，在 settings 文件中有这样的一条默认开启的语句。<br />
<p class="info-box">
	POBOTSOXT_OBEY = True</p>
robots.txt 是遵循 Robot 协议的一个文件，在 Scrapy 启动后，首先会访问网站的 robots.txt 文件，然后决定该网站的爬取范围。有时我们需要将此配置项设置为 False。在 settings.py 文件中，修改文件属性的方法如下。<br />
<p class="info-box">
	ROBOTSTXT_OBEY=False</p>
右击 E:\stockstar\stockstar 文件夹，在弹出的快捷菜单中选择&ldquo;Mark Directory as&rdquo;命令&rarr;选择&ldquo;Sources Root&rdquo;命令，这样可以使得导入包的语法更加简洁，如图 4 所示。
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q05454235_2.gif" /><br />
	图 4</div>
<h4>
	定义一个item容器</h4>
item 是存储爬取数据的容器，其使用方法和 Python 字典类似。它提供了额外的保护机制以避免拼写错误导致的未定义字段错误。<br />
<br />
首先需要对所要抓取的网页数据进行分析，定义所爬取记录的<a href='../data_structure/data_structure_2.html' target='_blank'>数据结构</a>。在相应的 items.py 中建立相应的字段，详细代码如下：<br />
<pre class="cpp">
import scrapy
from scrapy.loader import ItemLoader
from scrapy.loader.processors import TakeFirst
class StockstarItemLoader (ItemLoader):
#自定义itemloader,用于存储爬虫所抓取的字段内容
default_output_processor = TakeFirst()
class StockstarItem (scrapy.Item) : # 建立相应的字段
#define the fields for your item here like:
#name = scrapy.Field()
code = scrapy.Field() # 股票代码
abbr = scrapy.Field() # 股票简称
last_trade = scrapy.Field() # 最新价
chg_ratio = scrapy.Field() # 涨跌幅
chg_amt = scrapy.Field() # 涨跌额
chg_ratio_5min = scrapy.Field() # 5分钟涨幅
volumn = scrapy.Field() # 成交量
turn_over = scrapy.Field() # 成交额</pre>
<h4>
	定义settings文件进行基本爬虫设置</h4>
在相应的 settings.py 文件中定义可显示中文的 JSON Lines Exporter，并设置爬取间隔为 0.25 秒，详细代码如下：<br />
<pre class="cpp">
from scrapy.exporters import JsonLinesItemExporter #默认显示的中文是阅读性较差的Unicode字符
#需要定义子类显示出原来的字符集（将父类的ensure_ascii属性设置为False即可）
class CustomJsonLinesItemExporter(JsonLinesItemExporter):
    def __init__(self, file, **kwargs):
        super (CustomJsonLinesItemExporter, self).__init__(file, ensure_ascii=False, **kwargs)
    #启用新定义的Exporter类\
    FEED_EXPORTERS = {
        &#39;json&#39;:&#39;stockstar.settings.CustomJsonLinesItemExporter&#39;,
    }
    ...
    #Configure a delay for requests for the same website (default: 0)
    #See http:IIscrapy.readthedocs.org/en/latest/topics/settings.html#download-delay
    #See also autothrottle settings and docs DOWNLOAD DELAY = 0.25</pre>
<h4>
	编写爬虫逻辑</h4>
在编写爬虫逻辑之前，需要在 stockstar/spider 子文件下创建 .py 文件，用于定义爬虫的范围，也就是初始 URL。接下来定义一个名为 parse 的函数，用于解析服务器返回的内容。<br />
<br />
首先在 CMD 中输入代码，并生成 spider 代码，如下所示：<br />
<p class="info-box">
	cd stockstar<br />
	scrapy genspider stock quote.stockstar.com</p>
此时 spider 文件夹下面会创建后缀名为 stock.py 的文件，该文件会生成 start_url，即爬虫的起始地址，并且创建名为 parse 的自定义函数，之后的爬虫逻辑将在 parse 函数中书写。文件详情如图 5 所示：
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q05Q45X_2.gif" /><br />
	图 5</div>
<br />
代码详情如图 6 所示：
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q05S3644_2.gif" /><br />
	图 6</div>
<br />
随后在 spiders/stock.py 文件下，定义爬虫逻辑，详细代码如下：<br />
<pre class="cpp">
import scrapy
from items import StockstarItem, StockstarItemLoader\
class StockSpider(scrapy.Spider):
    name = &#39;stock&#39; #定义爬虫名称
    allowed_domains = [&#39;quote.stockstar.com&#39;] #定义爬虫域
    start_urls = [&#39;http://quote.stockstar.com/stock/ranklist_a_3_1_1.html&#39;]
    #定义开始爬虫链接
    def parse (self, response) : #撰写爬虫逻辑
    page = int (response.url.split(&quot;_&quot;)[-1].split(&quot;.&quot;)[0])#抓取页码
    item_nodes = response.css(&#39;#datalist tr&#39;)
    for item_node in item_nodes:
        #根据item文件中所定义的字段内容，进行字段内容的抓取
        item_loader = StockstarItemLoader(item=StockstarItem(), selector = item_node)
        item_loader.add_css(&quot;code&quot;, &quot;td:nth-child(1) a::text&quot;)
        item_loader.add_css(&quot;abbr&quot;, &quot;td:nth-child(2) a::text&quot;)
        item_loader.add_css(&quot;last_trade&quot;, &ldquo;td:nth-child(3) span::text&quot;)
        item_loader.add_css(&quot;chg_ratio&quot;, &quot;td:nth-child(4) span::text&quot;)
        item_loader.add_css(&quot;chg_amt&quot;, &quot;td:nth-child(5) span::text&quot;)
        item_loader.add_css(&quot;chg_ratio_5min&quot;,&quot;td:nth-child(6) span::text&quot;)
        item_loader.add_css(&quot;volumn&quot;, &quot;td:nth-child(7)::text&quot;)
        item_loader.add_css (&quot;turn_over&quot;, &quot;td:nth-child(8) :: text&quot;)
        stock_item = item_loader.load_item()
        yield stock_item
    if item_nodes:
        next_page = page + 1
        next_url = response.url.replace (&quot;{0}.html&quot;.format (page) , &quot;{0}.html&quot;.format(next_page))
        yield scrapy.Request(url=next_url, callback=self.parse)</pre>
<h4>
	代码调试</h4>
为了调试方便，在 E:\stockstar 下新建一个 main.py，调试代码如下：
<p class="info-box">
	from scrapy.cmdline import execute<br />
	execute([&quot;scrapy&quot;,&quot;crawl&quot;,&quot;stock&quot;,&quot;-o&quot;,&quot;items.json&quot;])</p>
其等价于在 E:\stockstar 下执行命令&ldquo;scrapy crawl stock-o items.json&rdquo;，将爬取的数据导出到 items.json 文件。<br />
<p class="info-box">
	E:\stockstar&gt;scrapy crawl stock -o items.json</p>
在代码里可设置断点（如在 spiders/stock.py 内），然后单击&ldquo;Run&rdquo;选项按钮&rarr;在弹出的菜单中选择&ldquo;Debug&lsquo;main&rsquo;&rdquo;命令，进行调试，如图 7 和图 8 所示。
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q05930519_2.gif" /><br />
	图 7</div>
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q059453W_2.gif" /><br />
	图 8</div>
<br />
最后在 PyCharm 中运行 Run＇main＇，运行界面如图 9 所示：
<div style="text-align: center;">
	<br />
	<img alt="" src="../uploads/allimg/190118/2-1Z11Q10005917_2.gif" /><br />
	图 9</div>
<br />
将所抓取的数据以 JSON 格式保存在 item 容器中。
<h2>
	知识扩展</h2>
本文从实战（抓取股票行情）出发讲解 Scrapy 框架，致力于让初学者快速了解 Python 爬虫 Scarpy 框架的使用。<br />
<br />
但本篇 Scarpy 实战毕竟篇幅有限，如果你想深入了解 Scrapy 框架，我推荐你阅读：
<ul>
	<li>
		<a href="https://www.cnblogs.com/oldcainiao/p/4489076.html" target="_blank">Scrapy框架入门&mdash;&mdash;老菜鸟</a></li>
	<li>
		<a href="https://www.jianshu.com/p/be856bc15afb" target="_blank">网络爬虫Scrapy中文教程&mdash;&mdash;简书</a></li>
	<li>
		<a href="http://www.runoob.com/w3cnote/scrapy-detail.html" target="_blank">Scrapy框架快速入门&mdash;&mdash;菜鸟教程</a></li>
</ul>
</div>
	<div id="ggxc-weixin-arcbottom">
	<p>关注公众号「<span class="col-green">站长严长生</span>」，在手机上阅读所有教程，随时随地都能学习。内含一款搜索神器，免费下载全网书籍和视频。</p>
	<p style="margin-top:12px; text-align:center;">
		<img src="../templets/new/images/material/qrcode_mp_4.png" alt="公众号二维码" width="160" /><br />
		<span class="col-green">微信扫码关注公众号</span>
	</p>
</div>
	<div id="nice-arcs" class="box-bottom">
    <h4>推荐阅读</h4>
    <ul class="clearfix">
<li><a href="niz69i_8.html" title="一套完整的嵌入式开发学习路线（高薪就业版）" target="_blank">一套完整的嵌入式开发学习路线（高薪就业版）</a></li>
<li><a href="tnnfqo_4.html" title="一套课程卖1万，TMD太贵了！" target="_blank">一套课程卖1万，TMD太贵了！</a></li>
<li><a href="unnurw_4.html" title="跑了3000公里，见了一位大佬" target="_blank">跑了3000公里，见了一位大佬</a></li>
<li><a href="729_2.html" title="Linux more命令：分屏显示文件内容" target="_blank">Linux more命令：分屏显示文件内容</a></li>
<li><a href="2311_2.html" title="C++重载&gt;&gt;和&lt;&lt;（输入和输出运算符）详解" target="_blank">C++重载&gt;&gt;和&lt;&lt;（输入和输出运算符）详解</a></li>
<li><a href="vip_7309_2.html" title="示例：聊天机器人" target="_blank">示例：聊天机器人</a></li>
<li><a href="7781_2.html" title="C++11 constexpr：验证是否为常量表达式（长篇神文）" target="_blank">C++11 constexpr：验证是否为常量表达式（长篇神文）</a></li>
<li><a href="9432_2.html" title="Qt打包程序详解（适用于Windows平台）" target="_blank">Qt打包程序详解（适用于Windows平台）</a></li>
<li><a href="../csharp/array_2.html" title="C#数组" target="_blank">C#数组</a></li>
<li><a href="d0rx484_2.html" title="测试工程师都干些什么工作？工资和程序员差得多吗？" target="_blank">测试工程师都干些什么工作？工资和程序员差得多吗？</a></li>
</ul>
</div>
	
</div>
<script type="text/javascript">
// 当前文章ID
window.arcIdRaw = 'a_' + 2027;
window.arcId = "b875NYxi+2avMLAavVcXAXmaoOe8J9O2ZCEC9oQs773kgzt0+hT6n65VusQ";
window.typeidChain = "145|119";
</script>
<div id="footer" class="clearfix">
	<div class="info left">
	<p>精美而实用的网站，分享优质编程教程，帮助有志青年。千锤百炼，只为大作；精益求精，处处斟酌；这种教程，看一眼就倾心。</p>
	<p>
		<a href="8066_2.html" target="_blank" rel="nofollow">关于网站</a> <span>|</span>
		<a href="8092_3.html" target="_blank" rel="nofollow">关于站长</a> <span>|</span>
		<a href="8097_2.html" target="_blank" rel="nofollow">如何完成一部教程</a> <span>|</span>
		<a href="9648_2.html" target="_blank" rel="nofollow">公众号</a> <span>|</span>
		<a href="8093_2.html" target="_blank" rel="nofollow">联系我们</a> <span>|</span>
		<a href="https://m.biancheng.net/sitemap/sitemap_2.html" target="_blank" rel="nofollow">网站地图</a>
	</p>
	<p>Copyright ©2012-2022 biancheng.net, <a href="https://beian.miit.gov.cn" target="_blank" rel="nofollow" style="color:#666;">冀ICP备2022013920号</a>, <img height="13" src="https://m.biancheng.net/templets/new/images/gongan_2.png" alt="公安备案图标" /><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13110202001352" target="_blank" rel="nofollow" style="color:#666;">冀公网安备13110202001352号</a>
	</p>
	</div>
	<img id="logo_bottom" class="right" src="https://m.biancheng.net/templets/new/images/logo_bottom_2.gif" alt="底部Logo" />
	<span id="return-top"><b>↑</b></span>
</div>

<div id="addweixin-widget">
	<p>
		<script type="text/javascript">
			/*var suffix = 'c';
			var thisMin = (new Date()).getMinutes();
			if(thisMin>=40){
				suffix = 'd';
			}else if(thisMin>=20){
				suffix = 'e';
			}else{
				suffix = 'c';
			}
			document.write('<img src="https://m.biancheng.net/templets/new/images/material/qrcode_wx_'%20+%20suffix%20+'.png?v=1.7.07" alt="微信交流群" width="120" /><br />');*/
		</script>
		<img src="https://m.biancheng.net/templets/new/images/material/qrcode_mp_4.png" alt="微信交流群" width="120" />
		<span>关注微信公众号，加入官方交流群。内含一款搜索神器，免费下载全网书籍和视频。</span>
	</p>
	<span id="close-addweixin-widget" class="iconfont iconfont-close"></span>
</div>

<script type="text/javascript">
window.siteId = 4;
window.cmsTemplets = "/templets/new";
window.cmsTempletsVer = "1.7.07";

</script>

<script src="https://m.biancheng.net/templets/new/script/jquery1.12.4.min_2.js"></script>
<script src="https://m.biancheng.net/templets/new/script/common_2.js"></script>
<!-- 51la V6 -->
<span style="display: none;">
<script charset="UTF-8" id="LA_COLLECT" src="https://sdk.51.la/js-sdk-pro.min.js"></script>
<script>LA.init({id:"KDf6QzBhogyQjall",ck:"KDf6QzBhogyQjall",autoTrack:true})</script>
</span>
<!-- 51la V5 -->
<!-- <span style="display: none;"><script type="text/javascript" src="https://js.users.51.la/21368967.js"></script></span> -->
</body>
</html>