<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="renderer" content="webkit" />
<meta name="force-rendering" content="webkit"/>
<meta name="applicable-device" content="pc,mobile" />
<meta name="MobileOptimized" content="width" />
<meta name="HandheldFriendly" content="true" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="format-detection" content="telephone=no" />
<link rel="shortcut icon" href="../favicon.ico" />
<link href="../templets/new/style/common.css" rel="stylesheet" />
<title>Pyhon爬虫下载小说</title>
<meta name="description" content="本节通过具体的爬虫程序，演示 BS4 解析库的实际应用。爬虫程序目标：下载诗词名句网（ https://www.shicimingju.com/book/ ）《 两晋演义 》小说。 关于分析网页分过程，这里不再做详细介绍" />
</head>
<body>
<div id="topbar" class="clearfix">
<ul id="product-type" class="left">
<li>
<a href="../c_biancheng_default.html"><span class="iconfont iconfont-home"></span>首页</a>
</li>
<li class="active">
<a href="../sitemap/sitemap_3.html" rel="nofollow"><span class="iconfont iconfont-book"></span>教程</a>
</li>
<li>
<a href="http://vip.biancheng.net/p/vip/show.php" rel="nofollow" target="_blank"><span class="iconfont iconfont-vip"></span>VIP会员</a>
</li>
<li>
<a href="../fudao_biancheng_default.html" rel="nofollow" target="_blank"><span class="iconfont iconfont-fudao"></span>辅导班</a>
</li>
<li>
<a href="../view/niz69i.html" target="_blank"><span class="iconfont iconfont-chip"></span>嵌入式学习路线</a>
</li>
</ul>
</div>
<div id="header" class="clearfix">
<a id="logo" class="left" href="../c_biancheng_default.html">
<img height="26" src="../templets/new/images/logo.png" alt="C语言中文网" />
</a>
<ul id="nav-main" class="hover-none left clearfix">
<li class="wap-yes"><a href="../c_biancheng_default.html">首页</a></li>
<li><a href="../c/c_3.html">C语言教程</a></li>
<li><a href="../cplus/cplus.html">C++教程</a></li>
<li><a href="../python/python.html">Python教程</a></li>
<li><a href="../java/java_3.html">Java教程</a></li>
<li><a href="../linux_tutorial/linux_tutorial.html">Linux入门</a></li>
<li><a href="../sitemap/sitemap_3.html" title="网站地图">更多&gt;&gt;</a></li>
</ul>
<span id="sidebar-toggle" class="toggle-btn" toggle-target="#sidebar">目录 <span class="iconfont"></span></span>
<a href="http://vip.biancheng.net/?from=topbar" class="user-info iconfont iconfont-user hover-none" target="_blank" rel="nofollow" title="用户中心"></a>
</div>
<div id="main" class="clearfix">
<div id="sidebar" class="toggle-target">
<div id="contents">
<dt><span class="iconfont iconfont-list-vertical" aria-hidden="true"></span><a href="python_spider.html">Python爬虫</a></dt>
<dd>
<span class="channel-num">1</span>
<a href="what-is-spider.html">网络爬虫是什么</a>
</dd>
<dd>
<span class="channel-num">2</span>
<a href="webpage.html">网页构成</a>
</dd>
<dd>
<span class="channel-num">3</span>
<a href="static-and-dynamic.html">静态网页和动态网页</a>
</dd>
<dd>
<span class="channel-num">4</span>
<a href="check-element.html">审查网页元素</a>
</dd>
<dd>
<span class="channel-num">5</span>
<a href="preparatory-work.html">学习前的准备工作</a>
</dd>
<dd>
<span class="channel-num">6</span>
<a href="the-first-spider.html">第一个Python爬虫程序</a>
</dd>
<dd>
<span class="channel-num">7</span>
<a href="user-agent.html">User-Agent用户代理</a>
</dd>
<dd>
<span class="channel-num">8</span>
<a href="useragent-pool.html">User-Agnet代理池</a>
</dd>
<dd>
<span class="channel-num">9</span>
<a href="url-coding.html">URL编码和解码</a>
</dd>
<dd>
<span class="channel-num">10</span>
<a href="crawl-webpage.html">[实例]爬虫抓取网页</a>
</dd>
<dd>
<span class="channel-num">11</span>
<a href="case01.html">[实例]抓取百度贴吧数据</a>
</dd>
<dd>
<span class="channel-num">12</span>
<a href="regexp-syntax.html">正则表达式语法</a>
</dd>
<dd>
<span class="channel-num">13</span>
<a href="re-module.html">Python re模块用法</a>
</dd>
<dd>
<span class="channel-num">14</span>
<a href="csv-module.html">Python csv模块</a>
</dd>
<dd>
<span class="channel-num">15</span>
<a href="case02.html">[实例]抓取猫眼电影排行榜</a>
</dd>
<dd>
<span class="channel-num">16</span>
<a href="pymysql.html">Python Pymysql存储数据</a>
</dd>
<dd>
<span class="channel-num">17</span>
<a href="case03.html">[实例]抓取多级页面数据</a>
</dd>
<dd>
<span class="channel-num">18</span>
<a href="requests.html">Python Requests库</a>
</dd>
<dd>
<span class="channel-num">19</span>
<a href="crawl-photo.html">[实例]抓取网络照片</a>
</dd>
<dd>
<span class="channel-num">20</span>
<a href="requests-args.html">Requests库方法和参数</a>
</dd>
<dd>
<span class="channel-num">21</span>
<a href="switchyomega.html">Proxy SwitchyOmeg</a>
</dd>
<dd>
<span class="channel-num">22</span>
<a href="xpath.html">Xpath简明教程</a>
</dd>
<dd>
<span class="channel-num">23</span>
<a href="xpath-helper.html">Xpath Helper安装使用</a>
</dd>
<dd>
<span class="channel-num">24</span>
<a href="lxml.html">Python lxml库</a>
</dd>
<dd>
<span class="channel-num">25</span>
<a href="lxml-case.html">[实例]Python lxml应用</a>
</dd>
<dd>
<span class="channel-num">26</span>
<a href="case04.html">[实例]抓取链家二手房数据</a>
</dd>
<dd>
<span class="channel-num">27</span>
<a href="capture-package.html">浏览器实现抓包</a>
</dd>
<dd>
<span class="channel-num">28</span>
<a href="case05.html">[实例]破解有道翻译</a>
</dd>
<dd>
<span class="channel-num">29</span>
<a href="case06.html">[实例]抓取动态加载数据</a>
</dd>
<dd>
<span class="channel-num">30</span>
<a href="json.html">Python json模块</a>
</dd>
<dd>
<span class="channel-num">31</span>
<a href="cookie-login.html">[实例]Cookie模拟登录</a>
</dd>
<dd>
<span class="channel-num">32</span>
<a href="multithreading.html">Python多线程爬虫</a>
</dd>
<dd>
<span class="channel-num">33</span>
<a href="bs4.html">Python BS4解析库</a>
</dd>
<dd>
<span class="channel-num">34</span>
<a href="case07.html">[实例]爬虫下载小说</a>
</dd>
<dd>
<span class="channel-num">35</span>
<a href="selenium.html">Selenium下载和安装</a>
</dd>
<dd>
<span class="channel-num">36</span>
<a href="selenium-using.html">Python Selenium用法</a>
</dd>
<dd>
<span class="channel-num">37</span>
<a href="selenium-case.html">[实例]Selenium实战应用</a>
</dd>
<dd>
<span class="channel-num">38</span>
<a href="scrapy.html">Python Scrapy爬虫框架</a>
</dd>
<dd>
<span class="channel-num">39</span>
<a href="scrapy-case.html">[实例]Scrapy框架应用</a>
</dd>
</div>
</div>
<div id="article-wrap">
<div id="article">
<div class="arc-info">
<span class="position"><span class="iconfont iconfont-home2"></span> <a href="../c_biancheng_default.html">首页</a> &gt; <a href="python_spider.html">Python爬虫</a></span>
</div>
<div id="ggxc-position-bottom" class="ggxc-box"></div>
<h1>Pyhon爬虫下载小说</h1>
<div class="pre-next-page clearfix">&nbsp;</div>
<div id="ggxc-arctop-pc-1" class="ggxc-box"></div>
<div id="arc-body">本节通过具体的爬虫程序，演示 BS4 解析库的实际应用。爬虫程序目标：下载诗词名句网（<a href="https://www.shicimingju.com/book/" target="_blank">https://www.shicimingju.com/book/</a>）《<a href="https://www.shicimingju.com/book/liangjinyanyi.html" target="_blank">两晋演义</a>》小说。<br />
<br />
关于分析网页分过程，这里不再做详细介绍了，只要通读了前面的文章，那么关于如何分析网页，此时您应该了然于胸了。其实，无论您爬取什么类型的网站，分析过程总是相似的。
<h2>
案例简单分析</h2>
首先判网站属于静态网站，因此您的主要任务是分析网页元素的组成，然后使用 BS4 提取所需的信息。如下所示：<br />
<br />
<div style="text-align: center;">
<img alt="网页元素分析" src="../uploads/allimg/210819/9-210Q9153303638.gif" /><br />
图1：网页元素分析</div>
<br />
提取到 a 标签是解决本程序的重点，a 标签的页面代码结构如下所示：
<pre class="html">
 
&lt;div class=&quot;book-mulu&quot;&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/book/liangjinyanyi/1.html&quot;&gt;自序&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/book/liangjinyanyi/2.html&quot;&gt;第一回　祀南郊司马开基　立东宫庸雏伏祸&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/book/liangjinyanyi/3.html&quot;&gt;第二回　堕诡计储君纳妇　慰痴情少女偷香&lt;/a&gt;&lt;/li&gt;
...
</pre>
从上述代码可以看出，a 标签包含了目录名称以及详情页的地址链接。那么如何获取 a 标签呢？经过简单分析后可知 a 标签属于 div &gt; ul &gt; li 的子节点，因此可以使用 BS4 的 select() 获取。如下所示：
<pre class="info-box">
list_name = soup.select(&#39;.book-mulu &gt; ul &gt; li &gt; a&#39;)</pre>
上述代码的返回值是一个列表，列表中每一个元素都是一个 Tag 对象，类型为&nbsp;<code style="font-size: 14px;">&lt;class &#39;bs4.element.Tag&#39;&gt;</code>。<br />
<br />
下载详情页的 URL 也非常容易获得，它是由发起请求的 URL 与 a 标签的 herf 链接拼接而成。因此通过字符串拼接就可以获取下载详内容页的 URL。
<pre class="info-box">
https://www.shicimingju.com/book/liangjinyanyi/2.html
https://www.shicimingju.com/book/liangjinyanyi/3.html
</pre>
最后一步是提取具体的内容。通过分析详情页的元素构成可知，我们想要的内容都包含在以下标签中：<br />
<pre class="info-box">
&lt;div class=&quot;chapter_content&quot;&gt;
具体内容
&lt;/div&gt;</pre>
因此使用 BS4 的 find() 方法就可以获取所需内容，如下所示：
<pre class="info-box">
artist = soup.find(&#39;div&#39;, class_=&#39;chapter_content&#39;)</pre>
之后把获取的内容写入到 txt 文件中就可以了。下面我使用之前学习过的 urllib 模块与 BS4 模块编写爬虫程序，这样才能做到温故而知新。
<h2>
编写爬虫程序</h2>
代码如下所示，程序中已经做了详细的注释：<br />
<pre class="python">
import urllib.request
import random
from bs4 import BeautifulSoup
import time
def request_html(url):
&nbsp;&nbsp;&nbsp; headers={&#39;User-Agent&#39;:&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36&#39;}
&nbsp;&nbsp;&nbsp; request = urllib.request.Request(url, headers=headers)
&nbsp;&nbsp;&nbsp; return request

def parse_html(html, f):
&nbsp;&nbsp;&nbsp; # 生成soup对象
&nbsp;&nbsp;&nbsp; soup = BeautifulSoup(html, &#39;lxml&#39;)
&nbsp;&nbsp;&nbsp; # 查找所有的章节链接和标题内容
&nbsp;&nbsp;&nbsp; list_name = soup.select(&#39;.book-mulu &gt; ul &gt; li &gt; a&#39;)
&nbsp;&nbsp;&nbsp; # 遍历每一个列表中的tag对象，获取链接个目录
&nbsp;&nbsp;&nbsp; for item in list_name:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 获取链接
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #item: &lt;a href=&quot;/book/liangjinyanyi/1.html&quot;&gt;自序&lt;/a&gt;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #拼接目录链接,此处item类型为&lt;class &#39;bs4.element.Tag&#39;&gt;，使用下面方法可以值获取href属性值
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; href = &#39;http://www.shicimingju.com&#39; + item[&#39;href&#39;]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 获取标题
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; title = item.text
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(&#39;正在下载:-**--%s--**-......&#39; % title)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 获取章节内容函数
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; text = get_text(href)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 写入文件
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; f.write(title + &#39;\n&#39; + text)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(&#39;结束下载:-**--%s--**-&#39; % title)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; time.sleep(random.uniform(0,1))

# 提取章节内容
def get_text(href):
&nbsp;&nbsp;&nbsp; #创建请求对象
&nbsp;&nbsp;&nbsp; request = request_html(href)
&nbsp;&nbsp;&nbsp; content = urllib.request.urlopen(request).read().decode(&#39;utf8&#39;)
&nbsp;&nbsp;&nbsp; soup = BeautifulSoup(content, &#39;lxml&#39;)
&nbsp;&nbsp;&nbsp; # 查找包含内容的tag--div
&nbsp;&nbsp;&nbsp; artist = soup.find(&#39;div&#39;, class_=&#39;chapter_content&#39;)
&nbsp;&nbsp;&nbsp; #获取tag标签中的文本内容
&nbsp;&nbsp;&nbsp; return artist.text

def run():
&nbsp;&nbsp;&nbsp; # 打开文件
&nbsp;&nbsp;&nbsp; f = open(&#39;两晋演义.txt&#39;, &#39;w&#39;, encoding=&#39;utf8&#39;)
&nbsp;&nbsp;&nbsp; url = &#39;http://www.shicimingju.com/book/liangjinyanyi.html&#39;
&nbsp;&nbsp;&nbsp; # 构建请求对象
&nbsp;&nbsp;&nbsp; request = request_html(url)
&nbsp;&nbsp;&nbsp; # 发送请求，得到响应，转换为HTML对象
&nbsp;&nbsp;&nbsp; html = urllib.request.urlopen(request).read().decode(&#39;utf8&#39;)
&nbsp;&nbsp;&nbsp; # 解析内容
&nbsp;&nbsp;&nbsp; parse_html(html,f)
&nbsp;&nbsp;&nbsp; #关闭文件
&nbsp;&nbsp;&nbsp; f.close()

if __name__ == &#39;__main__&#39;:
&nbsp;&nbsp;&nbsp; run()</pre>
程序运行结果：
<pre class="info-box">
正在下载:-**--自序--**-......
结束下载:-**--自序--**-
正在下载:-**--第一回　祀南郊司马开基　立东宫庸雏伏祸--**-......
结束下载:-**--第一回　祀南郊司马开基　立东宫庸雏伏祸--**-
正在下载:-**--第二回　堕诡计储君纳妇　慰痴情少女偷香--**-......
....</pre>
由于生成的 .txt 文件中内容过多，这里就不再做展示了。</div>
<div id="ggxc-weixin-arcbottom">
<p>关注公众号「<span class="col-green">站长严长生</span>」，在手机上阅读所有教程，随时随地都能学习。内含一款搜索神器，免费下载全网书籍和视频。</p>
<p style="margin-top:12px; text-align:center;">
<img src="../templets/new/images/material/qrcode_mp.png" alt="公众号二维码" width="160" /><br />
<span class="col-green">微信扫码关注公众号</span>
</p>
</div>
<div class="pre-next-page clearfix">&nbsp;</div>
<div id="nice-arcs" class="box-bottom">
<h4>推荐阅读</h4>
<ul class="clearfix">
<li><a href="../view/niz69i_4.html" title="一套完整的嵌入式开发学习路线（高薪就业版）" target="_blank">一套完整的嵌入式开发学习路线（高薪就业版）</a></li>
<li><a href="../view/tnnfqo_2.html" title="一套课程卖1万，TMD太贵了！" target="_blank">一套课程卖1万，TMD太贵了！</a></li>
<li><a href="../view/unnurw_2.html" title="跑了3000公里，见了一位大佬" target="_blank">跑了3000公里，见了一位大佬</a></li>
<li><a href="../view/413.html" title="C++ array迭代器及用法" target="_blank">C++ array迭代器及用法</a></li>
<li><a href="../view/716.html" title="dd命令安装Linux" target="_blank">dd命令安装Linux</a></li>
<li><a href="../css3/visibility.html" title="CSS visibility（元素可见性）" target="_blank">CSS visibility（元素可见性）</a></li>
<li><a href="../csharp/queue.html" title="C# Queue：队列" target="_blank">C# Queue：队列</a></li>
<li><a href="../view/3tw3k88.html" title="Go语言指针使用教程" target="_blank">Go语言指针使用教程</a></li>
<li><a href="../view/i0wfhmu.html" title="git pull命令：获取最新的远程仓库分支" target="_blank">git pull命令：获取最新的远程仓库分支</a></li>
<li><a href="../view/w0r2ljt.html" title="《明解C语言(中级篇)》PDF下载（高清完整版）" target="_blank">《明解C语言(中级篇)》PDF下载（高清完整版）</a></li>
</ul>
</div>
</div>
</div>
</div>
<script type="text/javascript">
// 当前文章ID
window.arcIdRaw = 'a_' + 9088;
window.arcId = "3d9431JFBcRU8+VJRKu36QbzxOwB2AmxbeZB516vbxhOyil0hi0ophRwyUs";
window.typeidChain = "421";
</script>
<div id="footer" class="clearfix">
<div class="info left">
<p>精美而实用的网站，分享优质编程教程，帮助有志青年。千锤百炼，只为大作；精益求精，处处斟酌；这种教程，看一眼就倾心。</p>
<p>
<a href="../view/8066.html" target="_blank" rel="nofollow">关于网站</a> <span>|</span>
<a href="../view/8092_2.html" target="_blank" rel="nofollow">关于站长</a> <span>|</span>
<a href="../view/8097.html" target="_blank" rel="nofollow">如何完成一部教程</a> <span>|</span>
<a href="../view/9648.html" target="_blank" rel="nofollow">公众号</a> <span>|</span>
<a href="../view/8093.html" target="_blank" rel="nofollow">联系我们</a> <span>|</span>
<a href="../sitemap/sitemap_3.html" target="_blank" rel="nofollow">网站地图</a>
</p>
<p>Copyright ©2012-2022 biancheng.net, <a href="https://beian.miit.gov.cn" target="_blank" rel="nofollow" style="color:#666;">冀ICP备2022013920号</a>, <img height="13" src="https://c.biancheng.net/templets/new/images/gongan.png" alt="公安备案图标" /><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13110202001352" target="_blank" rel="nofollow" style="color:#666;">冀公网安备13110202001352号</a>
</p>
</div>
<img id="logo_bottom" class="right" src="https://c.biancheng.net/templets/new/images/logo_bottom.gif" alt="底部Logo" />
<span id="return-top"><b>↑</b></span>
</div>
<div id="addweixin-widget">
<p>
<script type="text/javascript">
			/*var suffix = 'c';
			var thisMin = (new Date()).getMinutes();
			if(thisMin>=40){
				suffix = 'd';
			}else if(thisMin>=20){
				suffix = 'e';
			}else{
				suffix = 'c';
			}
			document.write('<img src="https://c.biancheng.net/templets/new/images/material/qrcode_wx_'%20+%20suffix%20+'.png?v=1.7.07" alt="微信交流群" width="120" /><br />');*/
		</script>
<img src="../templets/new/images/material/qrcode_mp_2.png" alt="微信交流群" width="120" />
<span>关注微信公众号，加入官方交流群。内含一款搜索神器，免费下载全网书籍和视频。</span>
</p>
<span id="close-addweixin-widget" class="iconfont iconfont-close"></span>
</div>
<script type="text/javascript">
window.siteId = 4;
window.cmsTemplets = "/templets/new";
window.cmsTempletsVer = "1.7.07";
window.prePageURL = "/python_spider/bs4.html";
window.nextPageURL = "/python_spider/selenium.html";
</script>
<script src="../templets/new/script/jquery1.12.4.min.js"></script>
<script src="https://c.biancheng.net/templets/new/script/common.js"></script>
<span style="display: none;">
<script charset="UTF-8" id="LA_COLLECT" src="https://sdk.51.la/js-sdk-pro.min.js"></script>
<script>LA.init({id:"KDf6QzBhogyQjall",ck:"KDf6QzBhogyQjall",autoTrack:true})</script>
</span>
</body>
</html>