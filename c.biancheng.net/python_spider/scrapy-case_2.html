<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ -->
<!-- 启用Chromium高速渲染模式 -->
<meta name="renderer" content="webkit" />
<meta name="force-rendering" content="webkit"/>
<!-- 禁止百度转码 -->
<meta name="applicable-device" content="pc,mobile" />
<meta name="MobileOptimized" content="width" />
<meta name="HandheldFriendly" content="true" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<!-- 禁止识别电话号码 -->
<meta name="format-detection" content="telephone=no" />

<link rel="shortcut icon" href="../favicon_3.ico" />
<link href="../templets/new/style/common_2.css" rel="stylesheet" />
<title>Python Scrapy爬虫框架实战应用</title>
<meta name="description" content="通过上一节《 Python Scrapy爬虫框架简介 》的学习，您已经对 Scrapy 框架有了一个初步的认识，比如它的组件构成，配置文件，以及工作流程。本节将通过一个的简单爬虫项目对 Scrapy 框架" />
</head>
<body>
<div id="topbar" class="clearfix">
	<ul id="product-type" class="left">
		<li>
			<a href="../m_biancheng_default_2.html"><span class="iconfont iconfont-home"></span>首页</a>
		</li>
		<li class="active">
			<a href="../sitemap/sitemap_2.html" rel="nofollow"><span class="iconfont iconfont-book"></span>教程</a>
		</li>
		<li>
			<a href="http://vip.biancheng.net/p/vip/show.php" rel="nofollow" target="_blank"><span class="iconfont iconfont-vip"></span>VIP会员</a>
		</li>
		<li>
			<a href="../fudao_biancheng_default.html" rel="nofollow" target="_blank"><span class="iconfont iconfont-fudao"></span>辅导班</a>
		</li>
		<li>
			<a href="../view/niz69i_5.html" target="_blank"><span class="iconfont iconfont-chip"></span>嵌入式学习路线</a>
		</li>
		<!-- <li>
			<a href="https://www.54benniao.com/c_course/?from=biancheng" target="_blank"><span class="iconfont iconfont-c-course"></span>C语言高级课程</a>
		</li>
		<li>
			<a href="https://www.54benniao.com/java_course/?from=biancheng" target="_blank"><span class="iconfont iconfont-java-course"></span>Java高级课程</a>
		</li>
		<li>
			<a href="http://vip.biancheng.net/p/q2a/show.php" rel="nofollow" target="_blank"><span class="iconfont iconfont-q2a"></span>一对一答疑</a>
		</li> -->
	</ul>
</div>
<div id="header" class="clearfix">
	<a id="logo" class="left" href="../m_biancheng_default_2.html">
		<img height="26" src="../templets/new/images/logo_2.png" alt="C语言中文网" />
	</a>
	<ul id="nav-main" class="hover-none left clearfix">
		<li class="wap-yes"><a href="../m_biancheng_default_2.html">首页</a></li>
		<li><a href="../c/c_4.html">C语言教程</a></li>
		<li><a href="../cplus/cplus_2.html">C++教程</a></li>
		<li><a href="../python/python_2.html">Python教程</a></li>
		<li><a href="../java/java_2.html">Java教程</a></li>
		<li><a href="../linux_tutorial/linux_tutorial_2.html">Linux入门</a></li>
		<li><a href="../sitemap/sitemap_2.html" title="网站地图">更多&gt;&gt;</a></li>
	</ul>
	<span id="sidebar-toggle" class="toggle-btn" toggle-target="#sidebar">目录 <span class="iconfont"></span></span>

	<a href="http://vip.biancheng.net/?from=topbar" class="user-info iconfont iconfont-user hover-none" target="_blank" rel="nofollow" title="用户中心"></a>
</div>
<div id="main" class="clearfix">
	<div id="sidebar" class="toggle-target">
	<div id="contents">
		<dt><span class="iconfont iconfont-list-vertical" aria-hidden="true"></span><a href="python_spider_2.html">Python爬虫</a></dt>
		<dd>
        	<span class="channel-num">1</span>
        	<a href="what-is-spider_2.html">网络爬虫是什么</a>
        </dd>
<dd>
        	<span class="channel-num">2</span>
        	<a href="webpage_2.html">网页构成</a>
        </dd>
<dd>
        	<span class="channel-num">3</span>
        	<a href="static-and-dynamic_2.html">静态网页和动态网页</a>
        </dd>
<dd>
        	<span class="channel-num">4</span>
        	<a href="check-element_2.html">审查网页元素</a>
        </dd>
<dd>
        	<span class="channel-num">5</span>
        	<a href="preparatory-work_2.html">学习前的准备工作</a>
        </dd>
<dd>
        	<span class="channel-num">6</span>
        	<a href="the-first-spider_2.html">第一个Python爬虫程序</a>
        </dd>
<dd>
        	<span class="channel-num">7</span>
        	<a href="user-agent_2.html">User-Agent用户代理</a>
        </dd>
<dd>
        	<span class="channel-num">8</span>
        	<a href="useragent-pool_2.html">User-Agnet代理池</a>
        </dd>
<dd>
        	<span class="channel-num">9</span>
        	<a href="url-coding_2.html">URL编码和解码</a>
        </dd>
<dd>
        	<span class="channel-num">10</span>
        	<a href="crawl-webpage_2.html">[实例]爬虫抓取网页</a>
        </dd>
<dd>
        	<span class="channel-num">11</span>
        	<a href="case01_2.html">[实例]抓取百度贴吧数据</a>
        </dd>
<dd>
        	<span class="channel-num">12</span>
        	<a href="regexp-syntax_2.html">正则表达式语法</a>
        </dd>
<dd>
        	<span class="channel-num">13</span>
        	<a href="re-module_2.html">Python re模块用法</a>
        </dd>
<dd>
        	<span class="channel-num">14</span>
        	<a href="csv-module_2.html">Python csv模块</a>
        </dd>
<dd>
        	<span class="channel-num">15</span>
        	<a href="case02_2.html">[实例]抓取猫眼电影排行榜</a>
        </dd>
<dd>
        	<span class="channel-num">16</span>
        	<a href="pymysql_2.html">Python Pymysql存储数据</a>
        </dd>
<dd>
        	<span class="channel-num">17</span>
        	<a href="case03_2.html">[实例]抓取多级页面数据</a>
        </dd>
<dd>
        	<span class="channel-num">18</span>
        	<a href="requests_2.html">Python Requests库</a>
        </dd>
<dd>
        	<span class="channel-num">19</span>
        	<a href="crawl-photo_2.html">[实例]抓取网络照片</a>
        </dd>
<dd>
        	<span class="channel-num">20</span>
        	<a href="requests-args_2.html">Requests库方法和参数</a>
        </dd>
<dd>
        	<span class="channel-num">21</span>
        	<a href="switchyomega_2.html">Proxy SwitchyOmeg</a>
        </dd>
<dd>
        	<span class="channel-num">22</span>
        	<a href="xpath_2.html">Xpath简明教程</a>
        </dd>
<dd>
        	<span class="channel-num">23</span>
        	<a href="xpath-helper_2.html">Xpath Helper安装使用</a>
        </dd>
<dd>
        	<span class="channel-num">24</span>
        	<a href="lxml_2.html">Python lxml库</a>
        </dd>
<dd>
        	<span class="channel-num">25</span>
        	<a href="lxml-case_2.html">[实例]Python lxml应用</a>
        </dd>
<dd>
        	<span class="channel-num">26</span>
        	<a href="case04_2.html">[实例]抓取链家二手房数据</a>
        </dd>
<dd>
        	<span class="channel-num">27</span>
        	<a href="capture-package_2.html">浏览器实现抓包</a>
        </dd>
<dd>
        	<span class="channel-num">28</span>
        	<a href="case05_2.html">[实例]破解有道翻译</a>
        </dd>
<dd>
        	<span class="channel-num">29</span>
        	<a href="case06_2.html">[实例]抓取动态加载数据</a>
        </dd>
<dd>
        	<span class="channel-num">30</span>
        	<a href="json_2.html">Python json模块</a>
        </dd>
<dd>
        	<span class="channel-num">31</span>
        	<a href="cookie-login_2.html">[实例]Cookie模拟登录</a>
        </dd>
<dd>
        	<span class="channel-num">32</span>
        	<a href="multithreading_2.html">Python多线程爬虫</a>
        </dd>
<dd>
        	<span class="channel-num">33</span>
        	<a href="bs4_2.html">Python BS4解析库</a>
        </dd>
<dd>
        	<span class="channel-num">34</span>
        	<a href="case07_2.html">[实例]爬虫下载小说</a>
        </dd>
<dd>
        	<span class="channel-num">35</span>
        	<a href="selenium_2.html">Selenium下载和安装</a>
        </dd>
<dd>
        	<span class="channel-num">36</span>
        	<a href="selenium-using_2.html">Python Selenium用法</a>
        </dd>
<dd>
        	<span class="channel-num">37</span>
        	<a href="selenium-case_2.html">[实例]Selenium实战应用</a>
        </dd>
<dd>
        	<span class="channel-num">38</span>
        	<a href="scrapy_2.html">Python Scrapy爬虫框架</a>
        </dd>
<dd>
        	<span class="channel-num">39</span>
        	<a href="scrapy-case_2.html">[实例]Scrapy框架应用</a>
        </dd>

	</div>
</div>
	<div id="article-wrap">
		<div id="article">
			<div class="arc-info">
	<span class="position"><span class="iconfont iconfont-home2"></span> <a href="../m_biancheng_default_2.html">首页</a> &gt; <a href="python_spider_2.html">Python爬虫</a></span>
</div>

<div id="ggxc-position-bottom" class="ggxc-box"></div>
			<h1>Python Scrapy爬虫框架实战应用</h1>
			<div class="pre-next-page clearfix">&nbsp;</div>
			<div id="ggxc-arctop-pc-1" class="ggxc-box"></div>
			<div id="arc-body">通过上一节《<a href="scrapy_2.html" target="_blank">Python Scrapy爬虫框架详解</a>》的学习，您已经对 Scrapy 框架有了一个初步的认识，比如它的组件构成，配置文件，以及工作流程。本节将通过一个的简单爬虫项目对 Scrapy 框架做进一步介绍。<br />
<br />
首先看一个简单的示例，比如把 C语言中文网首页的&ldquo;title&rdquo;抓取下来，如下所示：
<pre class="html">
&lt;html lang=&quot;zh-cn&quot;&gt;
&lt;head&gt;
&lt;meta charset=&quot;gb2312&quot; /&gt;
&lt;meta name=&quot;baidu-site-verification&quot; content=&quot;6B13HRSfYA&quot; /&gt;
&lt;link rel=&quot;shortcut icon&quot; href=&quot;/cpp/favicon.ico&quot; /&gt;
&lt;title&gt;C语言中文网：c语言程序设计门户网站(入门教程、编程软件)&lt;/title&gt;
....
&lt;/head&gt;</pre>
<h2>
	创建项目</h2>
在 CMD 命令行执行以下命令创建项目以及爬虫文件：
<pre class="info-box">
# 创建项目
1) scrapy startproject Title
# 进入项目
2) cd Title
# 创建爬虫文件
3）scrapy genspider title c.biancheng.net
</pre>
<h2>
	编写代码</h2>
打开爬虫文件 title.py ，编写如下代码，其中一些代码&nbsp; Scrapy 框架已经自动生成：
<h4>
	1) 编写爬虫文件</h4>
<pre class="python">
import scrapy
class TitleSpider(scrapy.Spider):

    name = &#39;title&#39;
    #要抓取数据的网站域名
    allowed_domains = [&#39;c.biancheng.net&#39;]
    #第一个抓取的url，初始url,被当做队列来处理
    start_urls = [&#39;http://c.biancheng.net/&#39;]
    
    def parse(self,response):

        #.extract()：提取文本内容,将列表中所有元素序列化为Unicode字符串
        #.extract_first()：提取列表中第1个文本内容
        # 以下是我们自己编写的代码，而自动生成的代码不用改动
        result = response.xpath(&#39;/html/head/title/text()&#39;).extract_first()
        print(&#39;-&#39; * 60 )
        print(result)
        print(&#39;-&#39; * 60)</pre>
<h4>
	2) 修改配置文件</h4>
下面修改 settings 文件的配置项，如下所示：
<pre class="info-box">
USER_AGENT = &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1&#39;
ROBOTSTXT_OBEY = False
DEFAULT_REQUEST_HEADERS = {
  &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;,
  &#39;Accept-Language&#39;: &#39;en&#39;,
}</pre>
<h4>
	3) 使用Pycharm IDE运行项目</h4>
为了省去终端敲命令的环节，您可以在项目中自定义一个运行文件 mian.py（注意：该文件与 scrapy.cfg 同目录），并编写如下代码：
<pre class="python">
from scrapy import cmdline
# 注意，cmdline.execute()是为了减少输入命令的操作，该方法的参数必须为列表。
# 执行爬虫文件来启动项目
cmdline.execute(&#39;scrapy crawl title&#39;.split())</pre>
编写完成后，执行 main.py 文件，您会看到很多的输出内容，内容大致如下：
<pre class="info-box">
# scrapy 框架运行时输出的日志，包含很多信息，比如版本信息，执行过程等等
2021-04-09 16:35:15 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: Title)
2021-04-09 16:35:15 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 
...
2021-04-09 16:35:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
...
2021-04-09 16:35:16 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://c.biancheng.net/&gt; (referer: None)
# 此处是我们要的信息
--------------------------------------------------
C语言中文网：c语言程序设计门户网站(入门教程、编程软件)
--------------------------------------------------
2021-04-09 16:35:16 [scrapy.core.engine] INFO: Closing spider (finished)
2021-04-09 16:35:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:  #描述Scrapy执行状态，如请求次数，时间，接受字节数等
{&#39;downloader/request_bytes&#39;: 231,
...
</pre>
上述过程中，我们只在 title.py 中使用 Xpath 做了解析数据的操作，就拿到了我们想要的数据。由此可见 URL 入队出队， 发起 request 请求，返回&nbsp; response 响应等操作都是由 Scrapy 框架自动完成的。
<p class="tip-box">
	在 Scrapy 框架中，每个模块之间既紧密联系，但又相互独立，这样的设计减少了代码之间耦合度，是代码简洁易懂。</p>
<h2>
	猫眼电影案例</h2>
最后，我们使用 Scrapy 框架完成一个完整的案例：抓取猫眼电影 Top100 榜。
<h4>
	1) 创建项目</h4>
<pre class="info-box">
scrapy startproject Maoyan100
#进入项目目录
cd Maoyan100
# 创建爬虫文件,注意url 一定要是网站域名
scrapy genspider maoyan www.maoyan.com</pre>
<h4>
	2) 定义数据结构</h4>
首先在 items.py 中定义要抓取的数据结构，如下所示：
<pre class="python">
name = scrapy.Field()
star = scrapy.Field()
time = scrapy.Field()</pre>
<h4>
	3) 编写爬虫文件</h4>
接下来编写爬虫文件 maoyan.py 代码如下所示：
<pre class="python">
import scrapy
from Maoyan100.items import Maoyan100Item

class Maoyan100Spider(scrapy.Spider):
    # name 指定爬虫文件名字
    name = &#39;maoyan&#39;
    allowed_domains = [&#39;maoyan.com&#39;]  # 网站域名
    start_urls = [&#39;https://maoyan.com/board/4?offset=0&#39;]  # 第一个要抓取的url
    offset = 0  #查询字符串参数

    # response 为 start_urls中影响对象
    def parse(self,response):
        # 基准xpath，匹配电影信息的dd节点对象列表
        dd_list = response.xpath(&#39;//dl[@class=&quot;board-wrapper&quot;]/dd&#39;)
        # 给items.py 中的类：Maoyan100Item（）实例化
        item = Maoyan100Item()
        for dd in dd_list:
            item[&#39;name&#39;] = dd.xpath(&#39;./a/@title&#39;).get().strip()  # 1.6以后版本使用   原来用 extract_first()
            item[&#39;star&#39;] = dd.xpath(&#39;.//p[@class=&quot;star&quot;]/text()&#39;).get().strip()
            item[&#39;time&#39;] = dd.xpath(&#39;.//p[@class=&quot;releasetime&quot;]/text()&#39;).get().strip()
            yield item
        if self.offset &lt; 90:  # 判断条件
            self.offset += 10
            url = &#39;https://maoyan.com/board/4?offset=&#39; + str(self.offset)
            # 把url交给secheduer入队列
            # response会自动传给 callback 回调的 parse()函数 
            #Scrapy.request()向url发起请求，并将响应结果交给回调的解析函数
            yield scrapy.Request(url=url, callback=self.parse)  </pre>
<h4>
	4) 实现数据存储</h4>
通过编写管道文件 pipelinse.py 文件实现数据的存储，将抓取的数据存放在 MySQL 数据库，这里需要提前建库、建表，因为前面章节已经创建过，此处不再赘述。代码编写如下：<br />
<pre class="python">
import pymysql
from Maoyan100.settings import *

class Maoyan100Pipeline(object):
    def process_item(self, item, spider):
        print(item[&#39;name&#39;], item[&#39;star&#39;], item[&#39;time&#39;])
        return item  # 多个管道有体现


# 存入mysql数据库的管道
class Maoyan100MysqlPipeline(object):
    #开始
    def open_spider(self, spider):
        # 爬虫项目启动，执行连接数据操作
        # 以下常量需要定义在settings配置文件中
        self.db = pymysql.connect(
            host=MYSQL_HOST,
            user=MYSQL_USER,
            password=MYSQL_PWD,
            database=MYSQL_DB,
            charset=MYSQL_CHARSET
        )
        self.cursor = self.db.cursor()
    # 向表中插入数据
    def process_item(self, item, spider):
        ins = &#39;insert into movieinfo values(%s,%s,%s)&#39;
        L = [
            item[&#39;name&#39;], item[&#39;star&#39;], item[&#39;time&#39;]
        ]
        self.cursor.execute(ins, L)
        self.db.commit()
        return item
   # 结束存放数据，在项目最后一步执行
    def close_spider(self, spider):
        # close_spider()函数只在所有数据抓取完毕后执行一次，
        self.cursor.close()
        self.db.close()
        print(&#39;执行了close_spider方法,项目已经关闭&#39;)</pre>
<h4>
	5) 定义启动文件</h4>
下面定义项目启动文件 run.py， 代码如下：<br />
<pre class="python">
from scrapy import cmdline
#执行爬虫文件 -o 指定输出文件的格式
cmdline.execute(&#39;scrapy crawl maoyan -o maoyan.csv&#39;.split()) #执行项目，并且将数据存csv文件格式</pre>
<p class="tip-box">
	注意：指定 -o 参数，可以将数据以特定的文件格式保存，比如 csv、txt、josn 等。</p>
<h4>
	6) 修改配置文件</h4>
最后修改配置文件，主要有修改以下内容：添加日志输出、激活管道 pipelines、定义数据库常量，以及其他一些常用选项，如下所示：
<pre class="info-box">
#设置 robots.txt 为False
ROBOTSTXT_OBEY = False
#设置日志级别： DEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; CRITICAL
#日志需要自己添加，配置文件中没有，在空白处添加即可
LOG_LEVEL=&#39;DEBUG&#39;
#定义日志输出文件
LOG_FILE=&#39;maoyan.log&#39;
#设置导出数据的编码格式
FEED_EXPORT_ENCODING=&#39;utf-8&#39;
#设置下载器延迟时间，秒为单位
DOWNLOAD_DELAY = 1
#请求头，添加useragent等信息
DEFAULT_REQUEST_HEADERS = {
  &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;,
  &#39;Accept-Language&#39;: &#39;en&#39;,
  &#39;User-Agent&#39;:&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1&#39;
}
#激活管道，并添加数据存放mysql的类，200为执行优先级
ITEM_PIPELINES = {
   &#39;Maoyan100.pipelines.Maoyan100Pipeline&#39;: 300,
    # 执行数据存储mysql
   &#39;Maoyan100.pipelines.Maoyan100MysqlPipeline&#39;: 200

}
#在配置文件末尾添加mysql常用变量
MYSQL_HOST=&#39;localhost&#39;
MYSQL_USER=&#39;root&#39;
MYSQL_PWD=&#39;123456&#39;
MYSQL_DB=&#39;maoyandb&#39;
MYSQL_CHARSET=&#39;utf8&#39;</pre>
最后执行 run.py 文件，日志文件 maoyan.log 内容大致如下:
<pre class="info-box">
2021-04-09 19:38:11 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: Maoyan100)
2021-04-09 19:38:11 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0
...
2021-04-09 19:38:13 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://maoyan.com/board/4?offset=0&gt;

{&#39;name&#39;: &#39;我不是药神&#39;, &#39;star&#39;: &#39;主演：徐峥,周一围,王传君&#39;, &#39;time&#39;: &#39;上映时间：2018-07-05&#39;}
2021-04-09 19:38:13 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://maoyan.com/board/4?offset=0&gt;

{&#39;name&#39;: &#39;肖申克的救赎&#39;,
&#39;star&#39;: &#39;主演：蒂姆&middot;罗宾斯,摩根&middot;弗里曼,鲍勃&middot;冈顿&#39;,
...</pre>
maoyan.csv 文件大致如下：
<pre class="info-box">
name,star,time
我不是药神,&quot;主演：徐峥,周一围,王传君&quot;,上映时间：2018-07-05
肖申克的救赎,&quot;主演：蒂姆&middot;罗宾斯,摩根&middot;弗里曼,鲍勃&middot;冈顿&quot;,上映时间：1994-09-10(加拿大)
绿皮书,&quot;主演：维果&middot;莫腾森,马赫沙拉&middot;阿里,琳达&middot;卡德里尼&quot;,上映时间：2019-03-01
海上钢琴师,&quot;主演：蒂姆&middot;罗斯,比尔&middot;努恩,克兰伦斯&middot;威廉姆斯三世&quot;,上映时间：2019-11-15
小偷家族,&quot;主演：中川雅也,安藤樱,松冈茉优&quot;,上映时间：2018-08-03
哪吒之魔童降世,&quot;主演：吕艳婷,囧森瑟夫,瀚墨&quot;,上映时间：2019-07-26
霸王别姬,&quot;主演：张国荣,张丰毅,巩俐&quot;,上映时间：1993-07-26
...
黑天鹅,&quot;主演：娜塔莉&middot;波特曼,文森特&middot;卡索,米拉&middot;库妮丝&quot;,上映时间：2010-09-01(意大利)</pre>
</div>
			<div id="ggxc-weixin-arcbottom">
	<p>关注公众号「<span class="col-green">站长严长生</span>」，在手机上阅读所有教程，随时随地都能学习。内含一款搜索神器，免费下载全网书籍和视频。</p>
	<p style="margin-top:12px; text-align:center;">
		<img src="../templets/new/images/material/qrcode_mp_4.png" alt="公众号二维码" width="160" /><br />
		<span class="col-green">微信扫码关注公众号</span>
	</p>
</div>
			<div class="pre-next-page clearfix">&nbsp;</div>
			<div id="nice-arcs" class="box-bottom">
    <h4>推荐阅读</h4>
    <ul class="clearfix">
<li><a href="../view/niz69i_8.html" title="一套完整的嵌入式开发学习路线（高薪就业版）" target="_blank">一套完整的嵌入式开发学习路线（高薪就业版）</a></li>
<li><a href="../view/tnnfqo_4.html" title="一套课程卖1万，TMD太贵了！" target="_blank">一套课程卖1万，TMD太贵了！</a></li>
<li><a href="../view/unnurw_4.html" title="跑了3000公里，见了一位大佬" target="_blank">跑了3000公里，见了一位大佬</a></li>
<li><a href="../view/474_2.html" title="VS“无法查找或打开PDB文件”是怎么回事？如何解决" target="_blank">VS“无法查找或打开PDB文件”是怎么回事？如何解决</a></li>
<li><a href="../view/1143_2.html" title="Linux restore命令：还原dump操作备份下的文件、目录或分区" target="_blank">Linux restore命令：还原dump操作备份下的文件、目录或分区</a></li>
<li><a href="../view/4402_2.html" title="Python set集合方法详解（全）" target="_blank">Python set集合方法详解（全）</a></li>
<li><a href="../maven2/build-test_2.html" title="Maven项目的构建与测试" target="_blank">Maven项目的构建与测试</a></li>
<li><a href="../mongodb2/projection_2.html" title="MongoDB投影（指定查询字段）" target="_blank">MongoDB投影（指定查询字段）</a></li>
<li><a href="../sql/unique_2.html" title="SQL UNIQUE：唯一约束" target="_blank">SQL UNIQUE：唯一约束</a></li>
<li><a href="../view/9562_2.html" title="大厂卡学历吗？普通大学能进吗？" target="_blank">大厂卡学历吗？普通大学能进吗？</a></li>
</ul>
</div>
		</div>
		
	</div>
</div>
<script type="text/javascript">
// 当前文章ID
window.arcIdRaw = 'a_' + 9093;
window.arcId = "c1f1cVW+2qGW+15VqZ+Ib+eBguzrd4DgytmVHHRzsvSoBc/bqoxV+JSJTAs";
window.typeidChain = "421";
</script>
<div id="footer" class="clearfix">
	<div class="info left">
	<p>精美而实用的网站，分享优质编程教程，帮助有志青年。千锤百炼，只为大作；精益求精，处处斟酌；这种教程，看一眼就倾心。</p>
	<p>
		<a href="../view/8066_2.html" target="_blank" rel="nofollow">关于网站</a> <span>|</span>
		<a href="../view/8092_3.html" target="_blank" rel="nofollow">关于站长</a> <span>|</span>
		<a href="../view/8097_2.html" target="_blank" rel="nofollow">如何完成一部教程</a> <span>|</span>
		<a href="../view/9648_2.html" target="_blank" rel="nofollow">公众号</a> <span>|</span>
		<a href="../view/8093_2.html" target="_blank" rel="nofollow">联系我们</a> <span>|</span>
		<a href="../sitemap/sitemap_2.html" target="_blank" rel="nofollow">网站地图</a>
	</p>
	<p>Copyright ©2012-2022 biancheng.net, <a href="https://beian.miit.gov.cn" target="_blank" rel="nofollow" style="color:#666;">冀ICP备2022013920号</a>, <img height="13" src="../templets/new/images/gongan_2.png" alt="公安备案图标" /><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13110202001352" target="_blank" rel="nofollow" style="color:#666;">冀公网安备13110202001352号</a>
	</p>
	</div>
	<img id="logo_bottom" class="right" src="https://m.biancheng.net/templets/new/images/logo_bottom_2.gif" alt="底部Logo" />
	<span id="return-top"><b>↑</b></span>
</div>

<div id="addweixin-widget">
	<p>
		<script type="text/javascript">
			/*var suffix = 'c';
			var thisMin = (new Date()).getMinutes();
			if(thisMin>=40){
				suffix = 'd';
			}else if(thisMin>=20){
				suffix = 'e';
			}else{
				suffix = 'c';
			}
			document.write('<img src="https://m.biancheng.net/templets/new/images/material/qrcode_wx_'%20+%20suffix%20+'.png?v=1.7.07" alt="微信交流群" width="120" /><br />');*/
		</script>
		<img src="https://m.biancheng.net/templets/new/images/material/qrcode_mp_4.png" alt="微信交流群" width="120" />
		<span>关注微信公众号，加入官方交流群。内含一款搜索神器，免费下载全网书籍和视频。</span>
	</p>
	<span id="close-addweixin-widget" class="iconfont iconfont-close"></span>
</div>

<script type="text/javascript">
window.siteId = 4;
window.cmsTemplets = "/templets/new";
window.cmsTempletsVer = "1.7.07";
window.prePageURL = "/python_spider/scrapy.html";
window.nextPageURL = "/python_spider/scrapy-case.html";
</script>

<script src="https://m.biancheng.net/templets/new/script/jquery1.12.4.min_2.js"></script>
<script src="https://m.biancheng.net/templets/new/script/common_2.js"></script>
<!-- 51la V6 -->
<span style="display: none;">
<script charset="UTF-8" id="LA_COLLECT" src="https://sdk.51.la/js-sdk-pro.min.js"></script>
<script>LA.init({id:"KDf6QzBhogyQjall",ck:"KDf6QzBhogyQjall",autoTrack:true})</script>
</span>
<!-- 51la V5 -->
<!-- <span style="display: none;"><script type="text/javascript" src="https://js.users.51.la/21368967.js"></script></span> -->
</body>
</html>