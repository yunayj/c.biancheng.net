<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ -->
<!-- 启用Chromium高速渲染模式 -->
<meta name="renderer" content="webkit" />
<meta name="force-rendering" content="webkit"/>
<!-- 禁止百度转码 -->
<meta name="applicable-device" content="pc,mobile" />
<meta name="MobileOptimized" content="width" />
<meta name="HandheldFriendly" content="true" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<!-- 禁止识别电话号码 -->
<meta name="format-detection" content="telephone=no" />

<link rel="shortcut icon" href="../favicon_3.ico" />
<link href="../templets/new/style/common_2.css" rel="stylesheet" />
<title>Python爬虫抓取百度贴吧数据</title>
<meta name="description" content="本节继续讲解 Python 爬虫实战案例：抓取百度贴吧（ https://tieba.baidu.com/ ）页面，比如 Python爬虫吧、编程吧，只抓取贴吧的前 5 个页面即可。本节我们将使用面向对象的编程方法来编写程" />
</head>
<body>
<div id="topbar" class="clearfix">
	<ul id="product-type" class="left">
		<li>
			<a href="../m_biancheng_default_2.html"><span class="iconfont iconfont-home"></span>首页</a>
		</li>
		<li class="active">
			<a href="../sitemap/sitemap_2.html" rel="nofollow"><span class="iconfont iconfont-book"></span>教程</a>
		</li>
		<li>
			<a href="http://vip.biancheng.net/p/vip/show.php" rel="nofollow" target="_blank"><span class="iconfont iconfont-vip"></span>VIP会员</a>
		</li>
		<li>
			<a href="../fudao_biancheng_default.html" rel="nofollow" target="_blank"><span class="iconfont iconfont-fudao"></span>辅导班</a>
		</li>
		<li>
			<a href="../view/niz69i_5.html" target="_blank"><span class="iconfont iconfont-chip"></span>嵌入式学习路线</a>
		</li>
		<!-- <li>
			<a href="https://www.54benniao.com/c_course/?from=biancheng" target="_blank"><span class="iconfont iconfont-c-course"></span>C语言高级课程</a>
		</li>
		<li>
			<a href="https://www.54benniao.com/java_course/?from=biancheng" target="_blank"><span class="iconfont iconfont-java-course"></span>Java高级课程</a>
		</li>
		<li>
			<a href="http://vip.biancheng.net/p/q2a/show.php" rel="nofollow" target="_blank"><span class="iconfont iconfont-q2a"></span>一对一答疑</a>
		</li> -->
	</ul>
</div>
<div id="header" class="clearfix">
	<a id="logo" class="left" href="../m_biancheng_default_2.html">
		<img height="26" src="../templets/new/images/logo_2.png" alt="C语言中文网" />
	</a>
	<ul id="nav-main" class="hover-none left clearfix">
		<li class="wap-yes"><a href="../m_biancheng_default_2.html">首页</a></li>
		<li><a href="../c/c_4.html">C语言教程</a></li>
		<li><a href="../cplus/cplus_2.html">C++教程</a></li>
		<li><a href="../python/python_2.html">Python教程</a></li>
		<li><a href="../java/java_2.html">Java教程</a></li>
		<li><a href="../linux_tutorial/linux_tutorial_2.html">Linux入门</a></li>
		<li><a href="../sitemap/sitemap_2.html" title="网站地图">更多&gt;&gt;</a></li>
	</ul>
	<span id="sidebar-toggle" class="toggle-btn" toggle-target="#sidebar">目录 <span class="iconfont"></span></span>

	<a href="http://vip.biancheng.net/?from=topbar" class="user-info iconfont iconfont-user hover-none" target="_blank" rel="nofollow" title="用户中心"></a>
</div>
<div id="main" class="clearfix">
	<div id="sidebar" class="toggle-target">
	<div id="contents">
		<dt><span class="iconfont iconfont-list-vertical" aria-hidden="true"></span><a href="python_spider_2.html">Python爬虫</a></dt>
		<dd>
        	<span class="channel-num">1</span>
        	<a href="what-is-spider_2.html">网络爬虫是什么</a>
        </dd>
<dd>
        	<span class="channel-num">2</span>
        	<a href="webpage_2.html">网页构成</a>
        </dd>
<dd>
        	<span class="channel-num">3</span>
        	<a href="static-and-dynamic_2.html">静态网页和动态网页</a>
        </dd>
<dd>
        	<span class="channel-num">4</span>
        	<a href="check-element_2.html">审查网页元素</a>
        </dd>
<dd>
        	<span class="channel-num">5</span>
        	<a href="preparatory-work_2.html">学习前的准备工作</a>
        </dd>
<dd>
        	<span class="channel-num">6</span>
        	<a href="the-first-spider_2.html">第一个Python爬虫程序</a>
        </dd>
<dd>
        	<span class="channel-num">7</span>
        	<a href="user-agent_2.html">User-Agent用户代理</a>
        </dd>
<dd>
        	<span class="channel-num">8</span>
        	<a href="useragent-pool_2.html">User-Agnet代理池</a>
        </dd>
<dd>
        	<span class="channel-num">9</span>
        	<a href="url-coding_2.html">URL编码和解码</a>
        </dd>
<dd>
        	<span class="channel-num">10</span>
        	<a href="crawl-webpage_2.html">[实例]爬虫抓取网页</a>
        </dd>
<dd>
        	<span class="channel-num">11</span>
        	<a href="case01_2.html">[实例]抓取百度贴吧数据</a>
        </dd>
<dd>
        	<span class="channel-num">12</span>
        	<a href="regexp-syntax_2.html">正则表达式语法</a>
        </dd>
<dd>
        	<span class="channel-num">13</span>
        	<a href="re-module_2.html">Python re模块用法</a>
        </dd>
<dd>
        	<span class="channel-num">14</span>
        	<a href="csv-module_2.html">Python csv模块</a>
        </dd>
<dd>
        	<span class="channel-num">15</span>
        	<a href="case02_2.html">[实例]抓取猫眼电影排行榜</a>
        </dd>
<dd>
        	<span class="channel-num">16</span>
        	<a href="pymysql_2.html">Python Pymysql存储数据</a>
        </dd>
<dd>
        	<span class="channel-num">17</span>
        	<a href="case03_2.html">[实例]抓取多级页面数据</a>
        </dd>
<dd>
        	<span class="channel-num">18</span>
        	<a href="requests_2.html">Python Requests库</a>
        </dd>
<dd>
        	<span class="channel-num">19</span>
        	<a href="crawl-photo_2.html">[实例]抓取网络照片</a>
        </dd>
<dd>
        	<span class="channel-num">20</span>
        	<a href="requests-args_2.html">Requests库方法和参数</a>
        </dd>
<dd>
        	<span class="channel-num">21</span>
        	<a href="switchyomega_2.html">Proxy SwitchyOmeg</a>
        </dd>
<dd>
        	<span class="channel-num">22</span>
        	<a href="xpath_2.html">Xpath简明教程</a>
        </dd>
<dd>
        	<span class="channel-num">23</span>
        	<a href="xpath-helper_2.html">Xpath Helper安装使用</a>
        </dd>
<dd>
        	<span class="channel-num">24</span>
        	<a href="lxml_2.html">Python lxml库</a>
        </dd>
<dd>
        	<span class="channel-num">25</span>
        	<a href="lxml-case_2.html">[实例]Python lxml应用</a>
        </dd>
<dd>
        	<span class="channel-num">26</span>
        	<a href="case04_2.html">[实例]抓取链家二手房数据</a>
        </dd>
<dd>
        	<span class="channel-num">27</span>
        	<a href="capture-package_2.html">浏览器实现抓包</a>
        </dd>
<dd>
        	<span class="channel-num">28</span>
        	<a href="case05_2.html">[实例]破解有道翻译</a>
        </dd>
<dd>
        	<span class="channel-num">29</span>
        	<a href="case06_2.html">[实例]抓取动态加载数据</a>
        </dd>
<dd>
        	<span class="channel-num">30</span>
        	<a href="json_2.html">Python json模块</a>
        </dd>
<dd>
        	<span class="channel-num">31</span>
        	<a href="cookie-login_2.html">[实例]Cookie模拟登录</a>
        </dd>
<dd>
        	<span class="channel-num">32</span>
        	<a href="multithreading_2.html">Python多线程爬虫</a>
        </dd>
<dd>
        	<span class="channel-num">33</span>
        	<a href="bs4_2.html">Python BS4解析库</a>
        </dd>
<dd>
        	<span class="channel-num">34</span>
        	<a href="case07_2.html">[实例]爬虫下载小说</a>
        </dd>
<dd>
        	<span class="channel-num">35</span>
        	<a href="selenium_2.html">Selenium下载和安装</a>
        </dd>
<dd>
        	<span class="channel-num">36</span>
        	<a href="selenium-using_2.html">Python Selenium用法</a>
        </dd>
<dd>
        	<span class="channel-num">37</span>
        	<a href="selenium-case_2.html">[实例]Selenium实战应用</a>
        </dd>
<dd>
        	<span class="channel-num">38</span>
        	<a href="scrapy_2.html">Python Scrapy爬虫框架</a>
        </dd>
<dd>
        	<span class="channel-num">39</span>
        	<a href="scrapy-case_2.html">[实例]Scrapy框架应用</a>
        </dd>

	</div>
</div>
	<div id="article-wrap">
		<div id="article">
			<div class="arc-info">
	<span class="position"><span class="iconfont iconfont-home2"></span> <a href="../m_biancheng_default_2.html">首页</a> &gt; <a href="python_spider_2.html">Python爬虫</a></span>
</div>

<div id="ggxc-position-bottom" class="ggxc-box"></div>
			<h1>Python爬虫抓取百度贴吧数据</h1>
			<div class="pre-next-page clearfix">&nbsp;</div>
			<div id="ggxc-arctop-pc-1" class="ggxc-box"></div>
			<div id="arc-body">本节继续讲解 Python 爬虫实战案例：抓取百度贴吧（<a href="https://tieba.baidu.com/" target="_blank">https://tieba.baidu.com/</a>）页面，比如 Python爬虫吧、编程吧，只抓取贴吧的前 5 个页面即可。本节我们将使用面向对象的编程方法来编写程序。<br />
<h2>
	判断页面类型</h2>
通过简单的分析可以得知，待抓取的百度贴吧页面属于静态网页，分析方法非常简单：打开百度贴吧，搜索&ldquo;Python爬虫&rdquo;，在出现的页面中复制任意一段信息，比如&ldquo;爬虫需要 http 代理的原因&rdquo;，然后点击右键选择查看源码，并使用 Ctrl+F 快捷键在源码页面搜索刚刚复制的数据，如下所示：<br />
<br />
<div style="text-align: center;">
	<img alt="静态网页判断" src="../uploads/allimg/210819/9-210Q9112J2329_2.png" /><br />
	图1：静态网页分析判断(<a href="../uploads/allimg/210819/9-210Q9112J2329_2.png" target="_blank">点击看高清图</a>)<br />
	&nbsp;</div>
由上图可知，页面内的所有信息都包含在源码页中，数据并不需要从数据库另行加载，因此该页面属于静态页面。
<h2>
	寻找URL变化规律</h2>
接下来寻找要爬取页面的 URL 规律，搜索&ldquo;Python爬虫&rdquo;后，此时贴吧第一页的的 url 如下所示：
<p class="info-box">
	https://tieba.baidu.com/f?ie=utf-8&amp;kw=python爬虫&amp;fr=search</p>
点击第二页，其 url 信息如下：
<p class="info-box">
	https://tieba.baidu.com/f?kw=python爬虫&amp;ie=utf-8&amp;pn=50</p>
点击第三页，url 信息如下：
<p class="info-box">
	https://tieba.baidu.com/f?kw=python爬虫&amp;ie=utf-8&amp;pn=100</p>
重新点击第一页，url 信息如下：
<p class="info-box">
	https://tieba.baidu.com/f?kw=python爬虫&amp;ie=utf-8&amp;pn=0</p>
如果还不确定，您可以继续多浏览几页。最后您发现 url 具有两个查询参数，分别是 kw 和 pn，并且 pn 参数具有规律性，如下所示：
<pre class="info-box">
第n页：pn=(n-1)*50

#参数params
pn=(page-1)*50
params={
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#39;kw&#39;:name,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&#39;pn&#39;:str(pn)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
</pre>
url 地址可以简写为：
<p class="info-box">
	https://tieba.baidu.com/f?kw=python爬虫&amp;pn=450</p>
<h2>
	编写爬虫程序</h2>
下面以类的形式编写爬虫程序，并在类下编写不同的功能函数，代码如下所示：<br />
<pre class="python">
from urllib import request,parse
import time
import random
from ua_info import ua_list #使用自定义的ua池

#定义一个爬虫类
class TiebaSpider(object):
    #初始化url属性
    def __init__(self):
        self.url=&#39;http://tieba.baidu.com/f?{}&#39;

    # 1.请求函数，得到页面，传统三步
    def get_html(self,url):
        req=request.Request(url=url,headers={&#39;User-Agent&#39;:random.choice(ua_list)})
        res=request.urlopen(req)
        #windows会存在乱码问题，需要使用 gbk解码，并使用ignore忽略不能处理的字节
        #linux不会存在上述问题，可以直接使用decode(&#39;utf-8&#39;)解码
        html=res.read().decode(&quot;gbk&quot;,&quot;ignore&quot;)
        return html
    # 2.解析函数，此处代码暂时省略，还没介绍解析模块
    def parse_html(self):
        pass
    # 3.保存文件函数
    def save_html(self,filename,html):
        with open(filename,&#39;w&#39;) as f:
            f.write(html)
    # 4.入口函数
    def run(self):
        name=input(&#39;输入贴吧名：&#39;)
        begin=int(input(&#39;输入起始页：&#39;))
        stop=int(input(&#39;输入终止页：&#39;))
        # +1 操作保证能够取到整数
        for page in range(begin,stop+1):
            pn=(page-1)*50
            params={
                &#39;kw&#39;:name,
                &#39;pn&#39;:str(pn)
            }
            #拼接URL地址   
            params=parse.urlencode(params)
            url=self.url.format(params)
            #发请求
            html=self.get_html(url)
            #定义路径
            filename=&#39;{}-{}页.html&#39;.format(name,page)
            self.save_html(filename,html)
            #提示
            print(&#39;第%d页抓取成功&#39;%page)
            #每爬取一个页面随机休眠1-2秒钟的时间
            time.sleep(random.randint(1,2))
#以脚本的形式启动爬虫
if __name__==&#39;__main__&#39;: 
    start=time.time()
    spider=TiebaSpider() #实例化一个对象spider
    spider.run() #调用入口函数
    end=time.time()
    #查看程序执行时间
    print(&#39;执行时间:%.2f&#39;%(end-start))  #爬虫执行时间</pre>
程序执行后，爬取的文件将会保存至 Pycharm 当前工作目录，输出结果：
<pre class="info-box">
输入贴吧名：python爬虫
输入起始页：1
输入终止页：2
第1页抓取成功
第2页抓取成功
执行时间:12.25</pre>
以面向对象方法编写爬虫程序时，思路简单、逻辑清楚，非常容易理解，上述代码主要包含了四个功能函数，它们分别负责了不同的功能，总结如下：
<h4>
	1) 请求函数</h4>
请求函数最终的结果是返回一个 HTML 对象，以方便后续的函数调用它。&nbsp;<br />
<h4>
	2) 解析函数</h4>
解析函数用来解析 HTML 页面，常用的解析模块有正则解析模块、bs4 解析模块。通过分析页面，提取出所需的数据，在后续内容会做详细介绍。<br />
<h4>
	3) 保存数据函数</h4>
该函数负责将抓取下来的数据保至数据库中，比如 MySQL、MongoDB 等，或者将其保存为文件格式，比如 csv、txt、excel 等。<br />
<h4>
	4) 入口函数</h4>
入口函数充当整个爬虫程序的桥梁，通过调用不同的功能函数，实现数据的最终抓取。入口函数的主要任务是组织数据，比如要搜索的贴吧名、编码 url 参数、拼接 url 地址、定义文件保存路径。
<h2>
	爬虫程序结构</h2>
用面向对象的方法编写爬虫程序时，逻辑结构较为固定，总结如下：
<pre class="python">
# 程序结构
class xxxSpider(object):
    def __init__(self):
        # 定义常用变量,比如url或计数变量等
       
    def get_html(self):
        # 获取响应内容函数,使用随机User-Agent
   
    def parse_html(self):
        # 使用正则表达式来解析页面，提取数据
   
    def write_html(self):
        # 将提取的数据按要求保存，csv、MySQL数据库等
       
    def run(self):
        # 主函数，用来控制整体逻辑
       
if __name__ == &#39;__main__&#39;:
    # 程序开始运行时间
    spider = xxxSpider()
    spider.run()
</pre>
注意：掌握以上编程逻辑有助于您后续的学习。
<h2>
	爬虫程序随机休眠</h2>
在入口函数代码中，包含了以下代码：
<pre class="python">
#每爬取一个页面随机休眠1-2秒钟的时间
time.sleep(random.randint(1,2))</pre>
爬虫程序访问网站会非常快，这与正常人类的点击行为非常不符。因此，通过随机休眠可以使爬虫程序模仿成人类的样子点击网站，从而让网站不易察觉是爬虫访问网站，但这样做的代价就是影响程序的执行效率。<br />
<p class="tip-box">
	聚焦爬虫是一种执行效率较低的程序，提升其性能，是业界一直关注的问题，由此也诞生了效率较高的 Python 爬虫框架 Scrapy。</p>
</div>
			<div id="ggxc-weixin-arcbottom">
	<p>关注公众号「<span class="col-green">站长严长生</span>」，在手机上阅读所有教程，随时随地都能学习。内含一款搜索神器，免费下载全网书籍和视频。</p>
	<p style="margin-top:12px; text-align:center;">
		<img src="../templets/new/images/material/qrcode_mp_4.png" alt="公众号二维码" width="160" /><br />
		<span class="col-green">微信扫码关注公众号</span>
	</p>
</div>
			<div class="pre-next-page clearfix">&nbsp;</div>
			<div id="nice-arcs" class="box-bottom">
    <h4>推荐阅读</h4>
    <ul class="clearfix">
<li><a href="../view/niz69i_8.html" title="一套完整的嵌入式开发学习路线（高薪就业版）" target="_blank">一套完整的嵌入式开发学习路线（高薪就业版）</a></li>
<li><a href="../view/tnnfqo_4.html" title="一套课程卖1万，TMD太贵了！" target="_blank">一套课程卖1万，TMD太贵了！</a></li>
<li><a href="../view/unnurw_4.html" title="跑了3000公里，见了一位大佬" target="_blank">跑了3000公里，见了一位大佬</a></li>
<li><a href="../view/1863_2.html" title="Qt QTableWidget及基本操作（详解版）" target="_blank">Qt QTableWidget及基本操作（详解版）</a></li>
<li><a href="../view/4643_2.html" title="Python __name__=='__main__'作用详解" target="_blank">Python __name__=='__main__'作用详解</a></li>
<li><a href="../view/7243_2.html" title="MySQL触发器到底是什么？" target="_blank">MySQL触发器到底是什么？</a></li>
<li><a href="../view/7580_2.html" title="Django模板过滤器用法详解" target="_blank">Django模板过滤器用法详解</a></li>
<li><a href="../view/vip_8327_2.html" title="实际应用中，需求分析阶段需要做什么？" target="_blank">实际应用中，需求分析阶段需要做什么？</a></li>
<li><a href="../redis2/hdel_2.html" title="Redis HDEL命令" target="_blank">Redis HDEL命令</a></li>
<li><a href="../view/6l3grgo_2.html" title="《单片机应用技术(C语言版)》第4版PDF下载（高清完整版）" target="_blank">《单片机应用技术(C语言版)》第4版PDF下载（高清完整版）</a></li>
</ul>
</div>
		</div>
		
	</div>
</div>
<script type="text/javascript">
// 当前文章ID
window.arcIdRaw = 'a_' + 9065;
window.arcId = "cc7058IxvOl30wY41oRoQZPt1s9rikL2RMmvxroju47KFJ5mnCE71muODKs";
window.typeidChain = "421";
</script>
<div id="footer" class="clearfix">
	<div class="info left">
	<p>精美而实用的网站，分享优质编程教程，帮助有志青年。千锤百炼，只为大作；精益求精，处处斟酌；这种教程，看一眼就倾心。</p>
	<p>
		<a href="../view/8066_2.html" target="_blank" rel="nofollow">关于网站</a> <span>|</span>
		<a href="../view/8092_3.html" target="_blank" rel="nofollow">关于站长</a> <span>|</span>
		<a href="../view/8097_2.html" target="_blank" rel="nofollow">如何完成一部教程</a> <span>|</span>
		<a href="../view/9648_2.html" target="_blank" rel="nofollow">公众号</a> <span>|</span>
		<a href="../view/8093_2.html" target="_blank" rel="nofollow">联系我们</a> <span>|</span>
		<a href="../sitemap/sitemap_2.html" target="_blank" rel="nofollow">网站地图</a>
	</p>
	<p>Copyright ©2012-2022 biancheng.net, <a href="https://beian.miit.gov.cn" target="_blank" rel="nofollow" style="color:#666;">冀ICP备2022013920号</a>, <img height="13" src="../templets/new/images/gongan_2.png" alt="公安备案图标" /><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13110202001352" target="_blank" rel="nofollow" style="color:#666;">冀公网安备13110202001352号</a>
	</p>
	</div>
	<img id="logo_bottom" class="right" src="https://m.biancheng.net/templets/new/images/logo_bottom_2.gif" alt="底部Logo" />
	<span id="return-top"><b>↑</b></span>
</div>

<div id="addweixin-widget">
	<p>
		<script type="text/javascript">
			/*var suffix = 'c';
			var thisMin = (new Date()).getMinutes();
			if(thisMin>=40){
				suffix = 'd';
			}else if(thisMin>=20){
				suffix = 'e';
			}else{
				suffix = 'c';
			}
			document.write('<img src="https://m.biancheng.net/templets/new/images/material/qrcode_wx_'%20+%20suffix%20+'.png?v=1.7.07" alt="微信交流群" width="120" /><br />');*/
		</script>
		<img src="https://m.biancheng.net/templets/new/images/material/qrcode_mp_4.png" alt="微信交流群" width="120" />
		<span>关注微信公众号，加入官方交流群。内含一款搜索神器，免费下载全网书籍和视频。</span>
	</p>
	<span id="close-addweixin-widget" class="iconfont iconfont-close"></span>
</div>

<script type="text/javascript">
window.siteId = 4;
window.cmsTemplets = "/templets/new";
window.cmsTempletsVer = "1.7.07";
window.prePageURL = "/python_spider/crawl-webpage.html";
window.nextPageURL = "/python_spider/regexp-syntax.html";
</script>

<script src="https://m.biancheng.net/templets/new/script/jquery1.12.4.min_2.js"></script>
<script src="https://m.biancheng.net/templets/new/script/common_2.js"></script>
<!-- 51la V6 -->
<span style="display: none;">
<script charset="UTF-8" id="LA_COLLECT" src="https://sdk.51.la/js-sdk-pro.min.js"></script>
<script>LA.init({id:"KDf6QzBhogyQjall",ck:"KDf6QzBhogyQjall",autoTrack:true})</script>
</span>
<!-- 51la V5 -->
<!-- <span style="display: none;"><script type="text/javascript" src="https://js.users.51.la/21368967.js"></script></span> -->
</body>
</html>