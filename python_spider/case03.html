<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="renderer" content="webkit" />
<meta name="force-rendering" content="webkit"/>
<meta name="applicable-device" content="pc,mobile" />
<meta name="MobileOptimized" content="width" />
<meta name="HandheldFriendly" content="true" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="format-detection" content="telephone=no" />
<link rel="shortcut icon" href="../favicon.ico" />
<link href="../templets/new/style/common.css" rel="stylesheet" />
<title>Python爬虫：抓取多级页面数据</title>
<meta name="description" content="前面讲解的爬虫案例，其实都是单级页面数据抓取，但是有些时候，只抓取一个单级页面是无法完成数据提取的。本节讲解如何使用爬虫抓取多级页面的数据。 在爬虫的过程中，多级页" />
</head>
<body>
<div id="topbar" class="clearfix">
<ul id="product-type" class="left">
<li>
<a href="../c_biancheng_default.html"><span class="iconfont iconfont-home"></span>首页</a>
</li>
<li class="active">
<a href="../sitemap/sitemap_3.html" rel="nofollow"><span class="iconfont iconfont-book"></span>教程</a>
</li>
<li>
<a href="http://vip.biancheng.net/p/vip/show.php" rel="nofollow" target="_blank"><span class="iconfont iconfont-vip"></span>VIP会员</a>
</li>
<li>
<a href="../fudao_biancheng_default.html" rel="nofollow" target="_blank"><span class="iconfont iconfont-fudao"></span>辅导班</a>
</li>
<li>
<a href="../view/niz69i.html" target="_blank"><span class="iconfont iconfont-chip"></span>嵌入式学习路线</a>
</li>
</ul>
</div>
<div id="header" class="clearfix">
<a id="logo" class="left" href="../c_biancheng_default.html">
<img height="26" src="../templets/new/images/logo.png" alt="C语言中文网" />
</a>
<ul id="nav-main" class="hover-none left clearfix">
<li class="wap-yes"><a href="../c_biancheng_default.html">首页</a></li>
<li><a href="../c/c_3.html">C语言教程</a></li>
<li><a href="../cplus/cplus.html">C++教程</a></li>
<li><a href="../python/python.html">Python教程</a></li>
<li><a href="../java/java_3.html">Java教程</a></li>
<li><a href="../linux_tutorial/linux_tutorial.html">Linux入门</a></li>
<li><a href="../sitemap/sitemap_3.html" title="网站地图">更多&gt;&gt;</a></li>
</ul>
<span id="sidebar-toggle" class="toggle-btn" toggle-target="#sidebar">目录 <span class="iconfont"></span></span>
<a href="http://vip.biancheng.net/?from=topbar" class="user-info iconfont iconfont-user hover-none" target="_blank" rel="nofollow" title="用户中心"></a>
</div>
<div id="main" class="clearfix">
<div id="sidebar" class="toggle-target">
<div id="contents">
<dt><span class="iconfont iconfont-list-vertical" aria-hidden="true"></span><a href="python_spider.html">Python爬虫</a></dt>
<dd>
<span class="channel-num">1</span>
<a href="what-is-spider.html">网络爬虫是什么</a>
</dd>
<dd>
<span class="channel-num">2</span>
<a href="webpage.html">网页构成</a>
</dd>
<dd>
<span class="channel-num">3</span>
<a href="static-and-dynamic.html">静态网页和动态网页</a>
</dd>
<dd>
<span class="channel-num">4</span>
<a href="check-element.html">审查网页元素</a>
</dd>
<dd>
<span class="channel-num">5</span>
<a href="preparatory-work.html">学习前的准备工作</a>
</dd>
<dd>
<span class="channel-num">6</span>
<a href="the-first-spider.html">第一个Python爬虫程序</a>
</dd>
<dd>
<span class="channel-num">7</span>
<a href="user-agent.html">User-Agent用户代理</a>
</dd>
<dd>
<span class="channel-num">8</span>
<a href="useragent-pool.html">User-Agnet代理池</a>
</dd>
<dd>
<span class="channel-num">9</span>
<a href="url-coding.html">URL编码和解码</a>
</dd>
<dd>
<span class="channel-num">10</span>
<a href="crawl-webpage.html">[实例]爬虫抓取网页</a>
</dd>
<dd>
<span class="channel-num">11</span>
<a href="case01.html">[实例]抓取百度贴吧数据</a>
</dd>
<dd>
<span class="channel-num">12</span>
<a href="regexp-syntax.html">正则表达式语法</a>
</dd>
<dd>
<span class="channel-num">13</span>
<a href="re-module.html">Python re模块用法</a>
</dd>
<dd>
<span class="channel-num">14</span>
<a href="csv-module.html">Python csv模块</a>
</dd>
<dd>
<span class="channel-num">15</span>
<a href="case02.html">[实例]抓取猫眼电影排行榜</a>
</dd>
<dd>
<span class="channel-num">16</span>
<a href="pymysql.html">Python Pymysql存储数据</a>
</dd>
<dd>
<span class="channel-num">17</span>
<a href="case03.html">[实例]抓取多级页面数据</a>
</dd>
<dd>
<span class="channel-num">18</span>
<a href="requests.html">Python Requests库</a>
</dd>
<dd>
<span class="channel-num">19</span>
<a href="crawl-photo.html">[实例]抓取网络照片</a>
</dd>
<dd>
<span class="channel-num">20</span>
<a href="requests-args.html">Requests库方法和参数</a>
</dd>
<dd>
<span class="channel-num">21</span>
<a href="switchyomega.html">Proxy SwitchyOmeg</a>
</dd>
<dd>
<span class="channel-num">22</span>
<a href="xpath.html">Xpath简明教程</a>
</dd>
<dd>
<span class="channel-num">23</span>
<a href="xpath-helper.html">Xpath Helper安装使用</a>
</dd>
<dd>
<span class="channel-num">24</span>
<a href="lxml.html">Python lxml库</a>
</dd>
<dd>
<span class="channel-num">25</span>
<a href="lxml-case.html">[实例]Python lxml应用</a>
</dd>
<dd>
<span class="channel-num">26</span>
<a href="case04.html">[实例]抓取链家二手房数据</a>
</dd>
<dd>
<span class="channel-num">27</span>
<a href="capture-package.html">浏览器实现抓包</a>
</dd>
<dd>
<span class="channel-num">28</span>
<a href="case05.html">[实例]破解有道翻译</a>
</dd>
<dd>
<span class="channel-num">29</span>
<a href="case06.html">[实例]抓取动态加载数据</a>
</dd>
<dd>
<span class="channel-num">30</span>
<a href="json.html">Python json模块</a>
</dd>
<dd>
<span class="channel-num">31</span>
<a href="cookie-login.html">[实例]Cookie模拟登录</a>
</dd>
<dd>
<span class="channel-num">32</span>
<a href="multithreading.html">Python多线程爬虫</a>
</dd>
<dd>
<span class="channel-num">33</span>
<a href="bs4.html">Python BS4解析库</a>
</dd>
<dd>
<span class="channel-num">34</span>
<a href="case07.html">[实例]爬虫下载小说</a>
</dd>
<dd>
<span class="channel-num">35</span>
<a href="selenium.html">Selenium下载和安装</a>
</dd>
<dd>
<span class="channel-num">36</span>
<a href="selenium-using.html">Python Selenium用法</a>
</dd>
<dd>
<span class="channel-num">37</span>
<a href="selenium-case.html">[实例]Selenium实战应用</a>
</dd>
<dd>
<span class="channel-num">38</span>
<a href="scrapy.html">Python Scrapy爬虫框架</a>
</dd>
<dd>
<span class="channel-num">39</span>
<a href="scrapy-case.html">[实例]Scrapy框架应用</a>
</dd>
</div>
</div>
<div id="article-wrap">
<div id="article">
<div class="arc-info">
<span class="position"><span class="iconfont iconfont-home2"></span> <a href="../c_biancheng_default.html">首页</a> &gt; <a href="python_spider.html">Python爬虫</a></span>
</div>
<div id="ggxc-position-bottom" class="ggxc-box"></div>
<h1>Python爬虫：抓取多级页面数据</h1>
<div class="pre-next-page clearfix">&nbsp;</div>
<div id="ggxc-arctop-pc-1" class="ggxc-box"></div>
<div id="arc-body">前面讲解的爬虫案例都是单级页面数据抓取，但有些时候，只抓取一个单级页面是无法完成数据提取的。本节讲解如何使用爬虫抓取多级页面的数据。<br />
<br />
在爬虫的过程中，多级页面抓取是经常遇见的。下面以抓取二级页面为例，对每级页面的作用进行说明：
<ul>
<li>
一级页面提供了获取二级页面的访问链接。</li>
<li>
二级页面作为详情页用来提取所需数据。</li>
</ul>
<br />
一级页面以<code style="font-size: 14px;">&lt;a&gt;</code>标签的形式链接到二级页面，只有在二级页面才可以提取到所需数据。
<h2>
多级页面分析</h2>
下面以电影天堂（<a href="https://www.dytt8.net/index.htm" target="_blank">点击访问</a>）&nbsp;2020 新片精品为案例进行讲解，将每部影片的名称，以及下载链接抓取下来。首先点击&ldquo;更多&rdquo;进入一级页面，如下图所示：<br />
<br />
<div style="text-align: center;">
<img alt="多级页面数据抓取" src="../uploads/allimg/210819/9-210Q9130T1100.png" /><br />
图1：Python爬虫多级页面抓取</div>
<h4>
1) 寻找url规律</h4>
通过简单分析可以得知一级与二级页面均为静态页面，接下来分析 url 规律，通过点击第 1 页，第 2 页 ...，其规律如下：
<pre class="info-box">
第1页 ：https://www.dytt8.net/html/gndy/dyzz/list_23_1.html
第2页 ：https://www.dytt8.net/html/gndy/dyzz/list_23_2.html
第n页 ：https://www.dytt8.net/html/gndy/dyzz/list_23_n.html</pre>
<h4>
2) 确定正则表达式</h4>
通过元素审查可知一级页面的元素结构如下：<br />
<br />
<div style="text-align: center;">
<img alt="一级页面元素结构" src="../uploads/allimg/210819/9-210Q9130U2593.gif" /><br />
图2：页面元素分析</div>
其正则表达式如下：
<pre class="info-box">
 &lt;table width=&quot;100%&quot;.*?&lt;td width=&quot;5%&quot;.*?&lt;a href=&quot;(.*?)&quot;.*?ulink&quot;&gt;.*?&lt;/table&gt;</pre>
<br />
点击二级页面进入详情页，通过开发者工具分析想要数据的网页元素，即电影名称，和下载链接，其正则表达式如下：
<pre class="info-box">
&lt;div class=&quot;title_all&quot;&gt;&lt;h1&gt;&lt;font color=#07519a&gt;(.*?)&lt;/font&gt;&lt;/h1&gt;&lt;/div&gt;.*?&lt;div&gt;&lt;a href=&quot;(.*?)&quot;&gt;.*?&lt;/a&gt;</pre>
<h2>
爬虫增量抓取</h2>
爬虫是一种效率很低的程序，非常消耗计算机资源。对于聚焦爬虫程序而言，需要每天对特定的网站进行数据抓取，如果每次都去抓取之前已经抓取过的数据，就会白白消耗了时间和资源。而增量爬虫是指通过监测网站更新的情况，只抓取最新数据的一种方式，这样就大大降低了资源的消耗。<br />
<br />
对于本节案例来说，电影天堂网站每天都会更新内容，因此编写一个增量抓取的爬虫程序是非常合适的。<br />
<br />
那么要如何判断爬虫程序是否已抓取过二级页面的 url 呢？其实，当您第一次运行爬虫程序时，爬虫会将所有的 url 抓取下来，然后将这些 url 放入数据库中。为了提高数据库的查询效率，您可以为每一个 url 生成专属的&ldquo;指纹&rdquo;。当网站更新后，第二次运行爬虫程序时，程序只会对数据库中不存在的指纹进行抓取。<br />
<h2>
程序代码实现</h2>
<h4>
1) 建库建表</h4>
将抓取的数据的存放至 MySQL 数据库，需要先进行建库建表操作。注意，这里需要将 url 指纹单独存放在一张表中，如下所示：
<pre class="sql">
create database movieskydb charset utf8;
use movieskydb;
create table request_finger(
finger char(60)
)charset=utf8;
create table movieinfo(
moviename varchar(300),
downloadaddr varchar(600)
)charset=utf8;</pre>
<h4>
2) url指纹生成</h4>
您可以使用 Python 内置模块 md5 来生成加密&ldquo;指纹&rdquo;，如下所示。&nbsp;
<pre class="python">
#导入模块
from hashlib import md5
#待加密的url
url=&quot;https://www.dytt8.net/html/gndy/dyzz/20210226/61131.html&quot;
# 生成MD5对象
secret = md5()
# 加密url
secret.update(url.encode())
# 提取十六进制的加密串
finger = secret.hexdigest()
print(finger)</pre>
输出结果：
<pre class="info-box">
2d5e46ee52756e8ae59c9ba42230b883</pre>
<h4>
3) 程序完整代码</h4>
<pre class="python">
# -*- coding: utf-8 -*-
from urllib import request
import re
import time
import random
import pymysql
from hashlib import md5
from ua_info import ua_list
import sys

class MovieSkySpider(object):
    def __init__(self):
        self.url = &#39;https://www.dytt8.net/html/gndy/dyzz/list_23_{}.html&#39;
        self.db = pymysql.connect(
            &#39;localhost&#39;,&#39;root&#39;,&#39;123456&#39;,&#39;movieskydb&#39;,
            charset=&#39;utf8&#39;
        )
        self.cursor = self.db.cursor()

    # 1.请求函数
    def get_html(self, url):
        headers = {&#39;User-Agent&#39;: random.choice(ua_list)}
        req = request.Request(url=url, headers=headers)
        res = request.urlopen(req)
        # 本网站使用gb2312的编码格式
        html = res.read().decode(&#39;gb2312&#39;, &#39;ignore&#39;)

        return html

    # 2.正则解析函数
    def re_func(self,re_bds,html):
        pattern = re.compile(re_bds,re.S)
        r_list = pattern.findall(html)

        return r_list

    # 3.提取数据函数
    def parse_html(self,one_url):
        # 调用请求函数，获取一级页面
        one_html = self.get_html(one_url)
        re_bds = &#39;&lt;table width=&quot;100%&quot;.*?&lt;td width=&quot;5%&quot;.*?&lt;a href=&quot;(.*?)&quot;.*?ulink&quot;&gt;.*?&lt;/table&gt;&#39;
        # 获取二级页面链接
        # link_list: [&#39;/html//html/gndy/dyzz/20210226/61131.html&#39;,&#39;/html/xxx&#39;,&#39;&#39;,&#39;&#39;]
        link_list = self.re_func(re_bds,one_html)
        for link in link_list:
            # 判断是否需要爬取此链接
            # 1.获取指纹
            # 拼接二级页面url
            two_url = &#39;https://www.dytt8.net&#39; + link
            s = md5()
            #加密url，需要是字节串
            s.update(two_url.encode())
            # 生成指纹，获取十六进制加密字符串，
            finger = s.hexdigest()
            # 2.通过函数判断指纹在数据库中是否存在
            if self.is_hold_on(finger):
                # 抓取二级页面数据
                self.save_html(two_url)
                time.sleep(random.randint(1,2))
                # 抓取后，把想用的url专属指纹存入数据库
                ins = &#39;insert into request_finger values (%s)&#39;
                self.cursor.execute(ins,[finger])
                self.db.commit()
            else:
                sys.exit(&#39;更新完成&#39;)

    # 4.判断链接是否已经抓取过
    def is_hold_on(self,finger):
        # 查询数据库
        sql=&#39;select finger from request_finger where finger=%s&#39;
        # execute()函数返回值为受影响的行数（即0或者非0）
        r = self.cursor.execute(sql,[finger])
        # 如果为0表示没有抓取过
        if not r:
            return True

    # 5.解析二级页面，获取数据（名称与下载链接）
    def save_html(self,two_url):
        two_html = self.get_html(two_url)
        re_bds = &#39;&lt;div class=&quot;title_all&quot;&gt;&lt;h1&gt;&lt;font color=#07519a&gt;(.*?)&lt;/font&gt;&lt;/h1&gt; \
        &lt;/div&gt;.*?&lt;a.*?href=&quot;(.*?)&quot;.*?&gt;.*?style=&quot;BACKGROUND-COLOR:.*?&lt;/a&gt;&#39;
        # film_list: [(&#39;name&#39;,&#39;downloadlink&#39;),(),(),()]
        film_list = self.re_func(re_bds,two_html)
        print(film_list)
        # 插入数据库
        sql = &#39;insert into movieinfo values(%s,%s)&#39;
        #L = list(film_list[0])
        self.cursor.executemany(sql,film_list)
        self.db.commit()
    
    #主函数 
    def run(self):
        # 二级页面后四页的正则表达式略有不同，需要重新分析
        for i in range(1,4):
            url = self.url.format(i)
            self.parse_html(url)

if __name__ == &#39;__main__&#39;:
    spider = MovieSkySpider()
    spider.run()</pre>
若要查询数据库存储数据，执行以下命令即可：
<pre class="sql">
mysql&gt; select * from movieinfo\G</pre>
输出如下，如下图所示：<br />
<br />
<div style="text-align: center;">
<img alt="Python爬虫多页面增量爬取" src="../uploads/allimg/210819/9-210Q9130Z1340.gif" /><br />
图3：MySQL数据库存储数据<br />
&nbsp;</div>
在二级页面提取数据时要注意该页面的类型。该网站在二级页面使用了两种类型的网页结构，另外一种页面结构的正则表达式如下所示：
<pre class="info-box">
&lt;div class=&quot;title_all&quot;&gt;&lt;h1&gt;&lt;font color=#07519a&gt;(.*?)&lt;/font&gt;&lt;/h1&gt;&lt;/div&gt;.*?&lt;td style=&quot;WORD-WRAP.*?&gt;.*?&gt;(.*?)&lt;/a&gt; </pre>
若要抓取此类页面的数据，需要更换二级页面正则表达式。</div>
<div id="ggxc-weixin-arcbottom">
<p>关注公众号「<span class="col-green">站长严长生</span>」，在手机上阅读所有教程，随时随地都能学习。内含一款搜索神器，免费下载全网书籍和视频。</p>
<p style="margin-top:12px; text-align:center;">
<img src="../templets/new/images/material/qrcode_mp.png" alt="公众号二维码" width="160" /><br />
<span class="col-green">微信扫码关注公众号</span>
</p>
</div>
<div class="pre-next-page clearfix">&nbsp;</div>
<div id="nice-arcs" class="box-bottom">
<h4>推荐阅读</h4>
<ul class="clearfix">
<li><a href="../view/niz69i_4.html" title="一套完整的嵌入式开发学习路线（高薪就业版）" target="_blank">一套完整的嵌入式开发学习路线（高薪就业版）</a></li>
<li><a href="../view/tnnfqo_2.html" title="一套课程卖1万，TMD太贵了！" target="_blank">一套课程卖1万，TMD太贵了！</a></li>
<li><a href="../view/unnurw_2.html" title="跑了3000公里，见了一位大佬" target="_blank">跑了3000公里，见了一位大佬</a></li>
<li><a href="../view/35.html" title="Go语言list（列表）" target="_blank">Go语言list（列表）</a></li>
<li><a href="../view/vip_1762.html" title="C语言整数的取值范围以及数值溢出" target="_blank">C语言整数的取值范围以及数值溢出</a></li>
<li><a href="../view/vip_6055.html" title="Python函数参数传递机制（超级详细）" target="_blank">Python函数参数传递机制（超级详细）</a></li>
<li><a href="../view/7364.html" title="MySQL查看索引（SHOW INDEX）" target="_blank">MySQL查看索引（SHOW INDEX）</a></li>
<li><a href="../view/8534.html" title="Java经典视频教程汇总，从入门到精通" target="_blank">Java经典视频教程汇总，从入门到精通</a></li>
<li><a href="../view/nlwxefu.html" title="Python write()方法：向文件中写入字符串" target="_blank">Python write()方法：向文件中写入字符串</a></li>
<li><a href="../view/4twxipr.html" title="Vue按键修饰符（keydown、keyup和keypress）" target="_blank">Vue按键修饰符（keydown、keyup和keypress）</a></li>
</ul>
</div>
</div>
</div>
</div>
<script type="text/javascript">
// 当前文章ID
window.arcIdRaw = 'a_' + 9071;
window.arcId = "2ac7rfwuptxDxFwx10t34vH3vEvt/QmH1mE6vAmx0AcMvFfCXRjs4EBtc7k";
window.typeidChain = "421";
</script>
<div id="footer" class="clearfix">
<div class="info left">
<p>精美而实用的网站，分享优质编程教程，帮助有志青年。千锤百炼，只为大作；精益求精，处处斟酌；这种教程，看一眼就倾心。</p>
<p>
<a href="../view/8066.html" target="_blank" rel="nofollow">关于网站</a> <span>|</span>
<a href="../view/8092_2.html" target="_blank" rel="nofollow">关于站长</a> <span>|</span>
<a href="../view/8097.html" target="_blank" rel="nofollow">如何完成一部教程</a> <span>|</span>
<a href="../view/9648.html" target="_blank" rel="nofollow">公众号</a> <span>|</span>
<a href="../view/8093.html" target="_blank" rel="nofollow">联系我们</a> <span>|</span>
<a href="../sitemap/sitemap_3.html" target="_blank" rel="nofollow">网站地图</a>
</p>
<p>Copyright ©2012-2022 biancheng.net, <a href="https://beian.miit.gov.cn" target="_blank" rel="nofollow" style="color:#666;">冀ICP备2022013920号</a>, <img height="13" src="../templets/new/images/gongan.png" alt="公安备案图标" /><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=13110202001352" target="_blank" rel="nofollow" style="color:#666;">冀公网安备13110202001352号</a>
</p>
</div>
<img id="logo_bottom" class="right" src="https://c.biancheng.net/templets/new/images/logo_bottom.gif" alt="底部Logo" />
<span id="return-top"><b>↑</b></span>
</div>
<div id="addweixin-widget">
<p>
<script type="text/javascript">
			/*var suffix = 'c';
			var thisMin = (new Date()).getMinutes();
			if(thisMin>=40){
				suffix = 'd';
			}else if(thisMin>=20){
				suffix = 'e';
			}else{
				suffix = 'c';
			}
			document.write('<img src="https://c.biancheng.net/templets/new/images/material/qrcode_wx_'%20+%20suffix%20+'.png?v=1.7.07" alt="微信交流群" width="120" /><br />');*/
		</script>
<img src="../templets/new/images/material/qrcode_mp_2.png" alt="微信交流群" width="120" />
<span>关注微信公众号，加入官方交流群。内含一款搜索神器，免费下载全网书籍和视频。</span>
</p>
<span id="close-addweixin-widget" class="iconfont iconfont-close"></span>
</div>
<script type="text/javascript">
window.siteId = 4;
window.cmsTemplets = "/templets/new";
window.cmsTempletsVer = "1.7.07";
window.prePageURL = "/python_spider/pymysql.html";
window.nextPageURL = "/python_spider/requests.html";
</script>
<script src="../templets/new/script/jquery1.12.4.min.js"></script>
<script src="https://c.biancheng.net/templets/new/script/common.js"></script>
<span style="display: none;">
<script charset="UTF-8" id="LA_COLLECT" src="https://sdk.51.la/js-sdk-pro.min.js"></script>
<script>LA.init({id:"KDf6QzBhogyQjall",ck:"KDf6QzBhogyQjall",autoTrack:true})</script>
</span>
</body>
</html>